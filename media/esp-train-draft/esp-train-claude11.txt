/*
 * ESP32-S3 On-Device CNN Training - BINARY CHECKPOINT VERSION
 * - Saves/Loads binary weights from /header/myWeights.bin (fast & reliable)
 * - Exports myModel.h for inference code
 * - Press A0 to continue training from checkpoint
 * 
 * SD Card Structure:
 *   /images/Class0_Name/  (e.g., /images/Rock/)
 *   /images/Class1_Name/  (e.g., /images/Paper/)
 *   /images/Class2_Name/  (e.g., /images/Scissors/)
 *   /header/myWeights.bin (binary checkpoint - loads automatically)
 *   /header/myModel.h     (C header for inference)
 */

#include "esp_camera.h"
#include "img_converters.h"
#include "FS.h"
#include "SD.h"
#include "SPI.h"
#include <vector>

// USER PARAMETERS - Can change and restart to continue training
#define USE_GRAYSCALE_MODE false
#define USE_INT8_QUANTIZATION false
float LEARNING_RATE = 0.001;
float DROPOUT_RATE = 0.3;
int BATCH_SIZE = 6;
int TARGET_EPOCHS = 10;
int MAX_IMAGES_PER_CLASS = 100;
bool USE_AUGMENTATION = true;
float BRIGHTNESS_RANGE = 0.2;
float CONTRAST_RANGE = 0.4;

// CAMERA PINS
#define XCLK_GPIO_NUM 10
#define SIOD_GPIO_NUM 40
#define SIOC_GPIO_NUM 39
#define Y9_GPIO_NUM 48
#define Y8_GPIO_NUM 11
#define Y7_GPIO_NUM 12
#define Y6_GPIO_NUM 14
#define Y5_GPIO_NUM 16
#define Y4_GPIO_NUM 18
#define Y3_GPIO_NUM 17
#define Y2_GPIO_NUM 15
#define VSYNC_GPIO_NUM 38
#define HREF_GPIO_NUM 47
#define PCLK_GPIO_NUM 13

// MODEL ARCHITECTURE
const int INPUT_CHANNELS = USE_GRAYSCALE_MODE ? 1 : 3;
const int FLATTENED_SIZE = 6728;

// WEIGHTS
float *conv1_w, *conv1_b, *conv2_w, *conv2_b, *dense_w, *dense_b;
float *conv1_w_grad, *conv1_b_grad, *conv2_w_grad, *conv2_b_grad, *dense_w_grad, *dense_b_grad;
float *conv1_w_m, *conv1_w_v, *conv1_b_m, *conv1_b_v;
float *conv2_w_m, *conv2_w_v, *conv2_b_m, *conv2_b_v;
float *dense_w_m, *dense_w_v, *dense_b_m, *dense_b_v;

// BUFFERS
float *input_buffer, *conv1_output, *pool1_output, *conv2_output, *dropout_mask, *dense_output;
float *dense_grad, *conv2_grad, *pool1_grad, *conv1_grad;

// DATA
struct TrainingImage { float* data; int label; };
std::vector<TrainingImage> training_data;
String class_labels[3];
int class_counts[3] = {0,0,0};

bool weights_loaded_from_checkpoint = false;

// UTILITY
inline float clip_value(float v, float mn=-100, float mx=100) {
  if(isnan(v)||isinf(v)) return 0;
  return constrain(v,mn,mx);
}
inline float leaky_relu(float x) { return x>0 ? x : 0.1f*x; }
inline float leaky_relu_deriv(float x) { return x>0 ? 1.0f : 0.1f; }
float random_float(float mn, float mx) { return mn + (float)random(10000)/10000.0f*(mx-mn); }

String toCString(String s) {
  s = s.substring(0,20);
  s.replace("\\","\\\\"); s.replace("\"","\\\""); s.replace("\n","\\n");
  return s;
}

// MEMORY ALLOCATION
bool allocate_model_memory() {
  Serial.println("\n=== Allocating Memory ===");
  int c1w_sz = 3*3*INPUT_CHANNELS*4;
  int c2w_sz = 3*3*4*8;
  int dw_sz = FLATTENED_SIZE*3;
  
  conv1_w = (float*)ps_malloc(c1w_sz*sizeof(float));
  conv1_b = (float*)ps_malloc(4*sizeof(float));
  conv2_w = (float*)ps_malloc(c2w_sz*sizeof(float));
  conv2_b = (float*)ps_malloc(8*sizeof(float));
  dense_w = (float*)ps_malloc(dw_sz*sizeof(float));
  dense_b = (float*)ps_malloc(3*sizeof(float));
  
  conv1_w_grad = (float*)ps_malloc(c1w_sz*sizeof(float));
  conv1_b_grad = (float*)ps_malloc(4*sizeof(float));
  conv2_w_grad = (float*)ps_malloc(c2w_sz*sizeof(float));
  conv2_b_grad = (float*)ps_malloc(8*sizeof(float));
  dense_w_grad = (float*)ps_malloc(dw_sz*sizeof(float));
  dense_b_grad = (float*)ps_malloc(3*sizeof(float));
  
  conv1_w_m = (float*)ps_calloc(c1w_sz, sizeof(float));
  conv1_w_v = (float*)ps_calloc(c1w_sz, sizeof(float));
  conv1_b_m = (float*)ps_calloc(4, sizeof(float));
  conv1_b_v = (float*)ps_calloc(4, sizeof(float));
  conv2_w_m = (float*)ps_calloc(c2w_sz, sizeof(float));
  conv2_w_v = (float*)ps_calloc(c2w_sz, sizeof(float));
  conv2_b_m = (float*)ps_calloc(8, sizeof(float));
  conv2_b_v = (float*)ps_calloc(8, sizeof(float));
  dense_w_m = (float*)ps_calloc(dw_sz, sizeof(float));
  dense_w_v = (float*)ps_calloc(dw_sz, sizeof(float));
  dense_b_m = (float*)ps_calloc(3, sizeof(float));
  dense_b_v = (float*)ps_calloc(3, sizeof(float));
  
  input_buffer = (float*)ps_malloc(64*64*INPUT_CHANNELS*sizeof(float));
  conv1_output = (float*)ps_malloc(62*62*4*sizeof(float));
  pool1_output = (float*)ps_malloc(31*31*4*sizeof(float));
  conv2_output = (float*)ps_malloc(29*29*8*sizeof(float));
  dropout_mask = (float*)ps_malloc(FLATTENED_SIZE*sizeof(float));
  dense_output = (float*)ps_malloc(3*sizeof(float));
  
  dense_grad = (float*)ps_malloc(FLATTENED_SIZE*sizeof(float));
  conv2_grad = (float*)ps_malloc(29*29*8*sizeof(float));
  pool1_grad = (float*)ps_malloc(31*31*4*sizeof(float));
  conv1_grad = (float*)ps_malloc(62*62*4*sizeof(float));
  
  if(!conv1_w || !conv2_w || !dense_w) { 
    Serial.println("[ERR] Memory allocation failed!"); 
    return false; 
  }
  Serial.printf("Free PSRAM: %d bytes\n", ESP.getFreePsram());
  return true;
}

// LOAD WEIGHTS FROM BINARY FILE (FAST & RELIABLE)
bool load_weights_from_binary() {
  Serial.println("\n=== Checking for checkpoint ===");
  
  if(!SD.exists("/header/myWeights.bin")) {
    Serial.println("No checkpoint found - will initialize random weights");
    return false;
  }
  
  Serial.println("Found /header/myWeights.bin - loading checkpoint...");
  
  File file = SD.open("/header/myWeights.bin", FILE_READ);
  if(!file) {
    Serial.println("[ERR] Cannot open checkpoint file");
    return false;
  }
  
  int c1w_sz = USE_GRAYSCALE_MODE ? 36 : 108;
  
  // Read weights in order
  file.read((uint8_t*)conv1_w, c1w_sz * sizeof(float));
  file.read((uint8_t*)conv1_b, 4 * sizeof(float));
  file.read((uint8_t*)conv2_w, 288 * sizeof(float));
  file.read((uint8_t*)conv2_b, 8 * sizeof(float));
  file.read((uint8_t*)dense_w, FLATTENED_SIZE * 3 * sizeof(float));
  file.read((uint8_t*)dense_b, 3 * sizeof(float));
  
  file.close();
  
  Serial.println("✓ Checkpoint loaded successfully!");
  Serial.println("  Optimizer state reset (momentum/velocity cleared)");
  
  // Reset Adam optimizer state for stability when changing learning rates
  memset(conv1_w_m, 0, c1w_sz*sizeof(float));
  memset(conv1_w_v, 0, c1w_sz*sizeof(float));
  memset(conv1_b_m, 0, 4*sizeof(float));
  memset(conv1_b_v, 0, 4*sizeof(float));
  memset(conv2_w_m, 0, 288*sizeof(float));
  memset(conv2_w_v, 0, 288*sizeof(float));
  memset(conv2_b_m, 0, 8*sizeof(float));
  memset(conv2_b_v, 0, 8*sizeof(float));
  memset(dense_w_m, 0, FLATTENED_SIZE*3*sizeof(float));
  memset(dense_w_v, 0, FLATTENED_SIZE*3*sizeof(float));
  memset(dense_b_m, 0, 3*sizeof(float));
  memset(dense_b_v, 0, 3*sizeof(float));
  
  return true;
}

// INITIALIZE RANDOM WEIGHTS
void initialize_weights() {
  Serial.println("Initializing random weights...");
  
  int c1w_sz = USE_GRAYSCALE_MODE ? 36 : 108;
  float c1std = sqrt(2.0/(9.0*INPUT_CHANNELS));
  for(int i=0; i<c1w_sz; i++) conv1_w[i] = random_float(-c1std, c1std);
  for(int i=0; i<4; i++) conv1_b[i] = 0;
  
  float c2std = sqrt(2.0/36.0);
  for(int i=0; i<288; i++) conv2_w[i] = random_float(-c2std, c2std);
  for(int i=0; i<8; i++) conv2_b[i] = 0;
  
  float dstd = sqrt(2.0/FLATTENED_SIZE);
  for(int i=0; i<FLATTENED_SIZE*3; i++) dense_w[i] = random_float(-dstd, dstd);
  for(int i=0; i<3; i++) dense_b[i] = 0;
}

// SAVE WEIGHTS TO BINARY FILE
bool save_weights_to_binary() {
  Serial.println("Saving binary checkpoint...");
  
  if(!SD.exists("/header")) {
    if(!SD.mkdir("/header")) {
      Serial.println("[ERR] Cannot create /header folder");
      return false;
    }
  }
  
  // Delete old file
  if(SD.exists("/header/myWeights.bin")) {
    SD.remove("/header/myWeights.bin");
    delay(100);
  }
  
  File file = SD.open("/header/myWeights.bin", FILE_WRITE);
  if(!file) {
    Serial.println("[ERR] Cannot create checkpoint file");
    return false;
  }
  
  int c1w_sz = USE_GRAYSCALE_MODE ? 36 : 108;
  
  // Write weights in order
  file.write((uint8_t*)conv1_w, c1w_sz * sizeof(float));
  file.write((uint8_t*)conv1_b, 4 * sizeof(float));
  file.write((uint8_t*)conv2_w, 288 * sizeof(float));
  file.write((uint8_t*)conv2_b, 8 * sizeof(float));
  file.write((uint8_t*)dense_w, FLATTENED_SIZE * 3 * sizeof(float));
  file.write((uint8_t*)dense_b, 3 * sizeof(float));
  
  file.close();
  Serial.println("✓ Binary checkpoint saved");
  return true;
}

// IMAGE LOADING
bool load_image_from_file(const char* path, float* buf) {
  File f = SD.open(path);
  if(!f) return false;
  
  size_t sz = f.size();
  uint8_t* jpg = (uint8_t*)ps_malloc(sz);
  if(!jpg) { f.close(); return false; }
  f.read(jpg, sz);
  f.close();
  
  uint8_t* rgb = (uint8_t*)ps_malloc(320*240*3);
  if(!rgb) { free(jpg); return false; }
  
  bool ok = fmt2rgb888(jpg, sz, PIXFORMAT_JPEG, rgb);
  free(jpg);
  if(!ok) { free(rgb); return false; }
  
  for(int y=0; y<64; y++) {
    for(int x=0; x<64; x++) {
      int sy = (int)((y+0.5)*240.0/64.0);
      int sx = (int)((x+0.5)*320.0/64.0);
      if(sy>239) sy=239;
      if(sx>319) sx=319;
      int idx = (sy*320+sx)*3;
      
      if(USE_GRAYSCALE_MODE) {
        buf[y*64+x] = (rgb[idx]*0.299 + rgb[idx+1]*0.587 + rgb[idx+2]*0.114)/255.0;
      } else {
        int b = (y*64+x)*3;
        buf[b] = rgb[idx]/255.0;
        buf[b+1] = rgb[idx+1]/255.0;
        buf[b+2] = rgb[idx+2]/255.0;
      }
    }
  }
  
  free(rgb);
  return true;
}

void load_images_from_sd() {
  Serial.println("\n=== Loading Images ===");
  
  File images_folder = SD.open("/images");
  if(!images_folder) { 
    Serial.println("[ERR] Cannot open /images folder"); 
    return; 
  }
  
  int cls = 0;
  File class_folder = images_folder.openNextFile();
  
  while(class_folder && cls < 3) {
    if(class_folder.isDirectory()) {
      String name = String(class_folder.name());
      
      if(name.startsWith(".") || name == "System Volume Information") {
        class_folder = images_folder.openNextFile();
        continue;
      }
      
      class_labels[cls] = name;
      Serial.printf("\nClass %d: %s\n", cls, name.c_str());
      
      File img = class_folder.openNextFile();
      int loaded = 0;
      
      while(img && loaded < MAX_IMAGES_PER_CLASS) {
        if(!img.isDirectory()) {
          String fn = String(img.name());
          if(fn.endsWith(".jpg") || fn.endsWith(".JPG")) {
            String path = "/images/" + name + "/" + fn;
            float* ib = (float*)ps_malloc(64*64*INPUT_CHANNELS*sizeof(float));
            if(ib && load_image_from_file(path.c_str(), ib)) {
              TrainingImage ti;
              ti.data = ib;
              ti.label = cls;
              training_data.push_back(ti);
              loaded++;
              class_counts[cls]++;
            } else {
              if(ib) free(ib);
            }
          }
        }
        img = class_folder.openNextFile();
      }
      
      Serial.printf("  Loaded: %d\n", loaded);
      cls++;
    }
    class_folder = images_folder.openNextFile();
  }
  
  Serial.printf("\nTotal: %d [%d,%d,%d]\n", training_data.size(), class_counts[0], class_counts[1], class_counts[2]);
}

void augment_image(float* src, float* dst) {
  int sz = 64*64*INPUT_CHANNELS;
  if(!USE_AUGMENTATION) { memcpy(dst, src, sz*sizeof(float)); return; }
  
  float br = random_float(-BRIGHTNESS_RANGE, BRIGHTNESS_RANGE);
  float co = random_float(1.0-CONTRAST_RANGE/2, 1.0+CONTRAST_RANGE/2);
  for(int i=0; i<sz; i++) {
    dst[i] = clip_value((src[i]-0.5)*co+0.5+br, 0.0, 1.0);
  }
}

// FORWARD PASS
void forward_conv1() {
  for(int f=0; f<4; f++) {
    int ob = f*3844;
    for(int y=0; y<62; y++) {
      for(int x=0; x<62; x++) {
        float s = 0;
        if(USE_GRAYSCALE_MODE) {
          for(int ky=0; ky<3; ky++)
            for(int kx=0; kx<3; kx++)
              s += input_buffer[(y+ky)*64+(x+kx)] * conv1_w[f*9+ky*3+kx];
        } else {
          for(int ky=0; ky<3; ky++) {
            for(int kx=0; kx<3; kx++) {
              int p = ((y+ky)*64+(x+kx))*3;
              int w = f*27+ky*9+kx*3;
              s += input_buffer[p]*conv1_w[w] + input_buffer[p+1]*conv1_w[w+1] + input_buffer[p+2]*conv1_w[w+2];
            }
          }
        }
        conv1_output[ob+y*62+x] = leaky_relu(clip_value(s+conv1_b[f]));
      }
    }
  }
}

void forward_pool1() {
  for(int f=0; f<4; f++) {
    int ib=f*3844, ob=f*961;
    for(int y=0; y<31; y++) {
      for(int x=0; x<31; x++) {
        int iy=y*2, ix=x*2;
        float m = conv1_output[ib+iy*62+ix];
        m = max(m, conv1_output[ib+iy*62+ix+1]);
        m = max(m, conv1_output[ib+(iy+1)*62+ix]);
        m = max(m, conv1_output[ib+(iy+1)*62+ix+1]);
        pool1_output[ob+y*31+x] = m;
      }
    }
  }
}

void forward_conv2() {
  for(int f=0; f<8; f++) {
    int ob=f*841;
    for(int y=0; y<29; y++) {
      for(int x=0; x<29; x++) {
        float s = 0;
        for(int c=0; c<4; c++) {
          int ib=c*961;
          for(int ky=0; ky<3; ky++)
            for(int kx=0; kx<3; kx++)
              s += pool1_output[ib+(y+ky)*31+(x+kx)] * conv2_w[f*36+c*9+ky*3+kx];
        }
        conv2_output[ob+y*29+x] = leaky_relu(clip_value(s+conv2_b[f]));
      }
    }
  }
}

void forward_dropout(bool training) {
  if(training && DROPOUT_RATE>0) {
    float kp = 1.0-DROPOUT_RATE;
    for(int i=0; i<FLATTENED_SIZE; i++) {
      dropout_mask[i] = (random_float(0,1)<kp) ? (1.0/kp) : 0.0;
      conv2_output[i] *= dropout_mask[i];
    }
  } else {
    for(int i=0; i<FLATTENED_SIZE; i++) dropout_mask[i] = 1.0;
  }
}

void forward_dense() {
  for(int c=0; c<3; c++) {
    double s=0, comp=0;
    for(int i=0; i<FLATTENED_SIZE; i++) {
      double t = conv2_output[i]*dense_w[c*FLATTENED_SIZE+i];
      double y = t-comp;
      double tt = s+y;
      comp = (tt-s)-y;
      s = tt;
    }
    dense_output[c] = clip_value((float)s+dense_b[c], -50, 50);
  }
  
  float mx = max(max(dense_output[0], dense_output[1]), dense_output[2]);
  float es = exp(dense_output[0]-mx) + exp(dense_output[1]-mx) + exp(dense_output[2]-mx);
  for(int i=0; i<3; i++) dense_output[i] = exp(dense_output[i]-mx)/es;
}

// BACKWARD PASS
void backward_dense(int lbl) {
  for(int c=0; c<3; c++) {
    float e = dense_output[c] - (c==lbl ? 1.0f : 0.0f);
    for(int i=0; i<FLATTENED_SIZE; i++) {
      dense_w_grad[c*FLATTENED_SIZE+i] = e*conv2_output[i];
      dense_grad[i] = (c==0) ? e*dense_w[c*FLATTENED_SIZE+i] : dense_grad[i]+e*dense_w[c*FLATTENED_SIZE+i];
    }
    dense_b_grad[c] = e;
  }
}

void backward_dropout() {
  for(int i=0; i<FLATTENED_SIZE; i++) dense_grad[i] *= dropout_mask[i];
}

void backward_conv2() {
  for(int i=0; i<FLATTENED_SIZE; i++) conv2_grad[i] = dense_grad[i]*leaky_relu_deriv(conv2_output[i]);
  
  memset(conv2_w_grad, 0, 288*sizeof(float));
  memset(conv2_b_grad, 0, 8*sizeof(float));
  memset(pool1_grad, 0, 3844*sizeof(float));
  
  for(int f=0; f<8; f++) {
    int ob=f*841;
    for(int y=0; y<29; y++) {
      for(int x=0; x<29; x++) {
        float g = conv2_grad[ob+y*29+x];
        conv2_b_grad[f] += g;
        for(int c=0; c<4; c++) {
          int ib=c*961;
          for(int ky=0; ky<3; ky++) {
            for(int kx=0; kx<3; kx++) {
              int pi = ib+(y+ky)*31+(x+kx);
              int wi = f*36+c*9+ky*3+kx;
              conv2_w_grad[wi] += g*pool1_output[pi];
              pool1_grad[pi] += g*conv2_w[wi];
            }
          }
        }
      }
    }
  }
}

void backward_pool1() {
  memset(conv1_grad, 0, 15376*sizeof(float));
  for(int f=0; f<4; f++) {
    int ib=f*3844, ob=f*961;
    for(int y=0; y<31; y++) {
      for(int x=0; x<31; x++) {
        int iy=y*2, ix=x*2;
        float pv = pool1_output[ob+y*31+x];
        float g = pool1_grad[ob+y*31+x];
        if(conv1_output[ib+iy*62+ix] == pv) conv1_grad[ib+iy*62+ix] += g;
        if(conv1_output[ib+iy*62+ix+1] == pv) conv1_grad[ib+iy*62+ix+1] += g;
        if(conv1_output[ib+(iy+1)*62+ix] == pv) conv1_grad[ib+(iy+1)*62+ix] += g;
        if(conv1_output[ib+(iy+1)*62+ix+1] == pv) conv1_grad[ib+(iy+1)*62+ix+1] += g;
      }
    }
  }
}

void backward_conv1() {
  for(int i=0; i<15376; i++) conv1_grad[i] *= leaky_relu_deriv(conv1_output[i]);
  
  int wsz = USE_GRAYSCALE_MODE ? 36 : 108;
  memset(conv1_w_grad, 0, wsz*sizeof(float));
  memset(conv1_b_grad, 0, 4*sizeof(float));
  
  for(int f=0; f<4; f++) {
    int ob=f*3844;
    for(int y=0; y<62; y++) {
      for(int x=0; x<62; x++) {
        float g = conv1_grad[ob+y*62+x];
        conv1_b_grad[f] += g;
        
        if(USE_GRAYSCALE_MODE) {
          for(int ky=0; ky<3; ky++)
            for(int kx=0; kx<3; kx++)
              conv1_w_grad[f*9+ky*3+kx] += g*input_buffer[(y+ky)*64+(x+kx)];
        } else {
          for(int ky=0; ky<3; ky++) {
            for(int kx=0; kx<3; kx++) {
              int p = ((y+ky)*64+(x+kx))*3;
              int w = f*27+ky*9+kx*3;
              conv1_w_grad[w] += g*input_buffer[p];
              conv1_w_grad[w+1] += g*input_buffer[p+1];
              conv1_w_grad[w+2] += g*input_buffer[p+2];
            }
          }
        }
      }
    }
  }
}

// ADAM OPTIMIZER
void adam_update(float* w, float* g, float* m, float* v, int sz, int step) {
  float b1=0.9, b2=0.999, eps=1e-8;
  float lr_t = LEARNING_RATE * sqrt(1-pow(b2,step)) / (1-pow(b1,step));
  for(int i=0; i<sz; i++) {
    m[i] = b1*m[i] + (1-b1)*g[i];
    v[i] = b2*v[i] + (1-b2)*g[i]*g[i];
    w[i] -= lr_t*m[i]/(sqrt(v[i])+eps);
    w[i] = clip_value(w[i], -10, 10);
  }
}

void update_weights(int step) {
  int c1sz = USE_GRAYSCALE_MODE ? 36 : 108;
  adam_update(conv1_w, conv1_w_grad, conv1_w_m, conv1_w_v, c1sz, step);
  adam_update(conv1_b, conv1_b_grad, conv1_b_m, conv1_b_v, 4, step);
  adam_update(conv2_w, conv2_w_grad, conv2_w_m, conv2_w_v, 288, step);
  adam_update(conv2_b, conv2_b_grad, conv2_b_m, conv2_b_v, 8, step);
  adam_update(dense_w, dense_w_grad, dense_w_m, dense_w_v, FLATTENED_SIZE*3, step);
  adam_update(dense_b, dense_b_grad, dense_b_m, dense_b_v, 3, step);
}

// TRAINING
void train_model() {
  Serial.println("\n======== TRAINING START ========");
  // Check current state - if weights were modified, we're continuing
  Serial.println("Training from current weights (no re-initialization)");
  
  int total = training_data.size();
  int batches_per_epoch = (total + BATCH_SIZE - 1) / BATCH_SIZE;
  int total_batches = TARGET_EPOCHS * batches_per_epoch;
  
  Serial.printf("Batches per epoch: %d, Total batches: %d\n\n", batches_per_epoch, total_batches);
  
  std::vector<int> indices;
  for(int i=0; i<total; i++) indices.push_back(i);
  
  float running_loss = 0;
  int loss_count = 0;
  
  for(int batch=0; batch<total_batches; batch++) {
    if(batch % batches_per_epoch == 0) {
      Serial.printf("\n--- Epoch %d/%d ---\n", batch/batches_per_epoch + 1, TARGET_EPOCHS);
      for(int i=total-1; i>0; i--) {
        int j = random(i+1);
        int tmp = indices[i];
        indices[i] = indices[j];
        indices[j] = tmp;
      }
    }
    
    int batch_start = (batch % batches_per_epoch) * BATCH_SIZE;
    int batch_end = min(batch_start + BATCH_SIZE, total);
    
    float batch_loss = 0;
    int correct = 0;
    
    for(int i=batch_start; i<batch_end; i++) {
      int idx = indices[i];
      TrainingImage& img = training_data[idx];
      
      augment_image(img.data, input_buffer);
      
      forward_conv1();
      forward_pool1();
      forward_conv2();
      forward_dropout(true);
      forward_dense();
      
      backward_dense(img.label);
      backward_dropout();
      backward_conv2();
      backward_pool1();
      backward_conv1();
      
      float loss = 0;
      for(int c=0; c<3; c++) {
        float target = (c == img.label) ? 1.0f : 0.0f;
        loss -= target * log(max(dense_output[c], 1e-7f));
      }
      batch_loss += loss;
      
      int pred = (dense_output[1]>dense_output[0]) ? 1 : 0;
      if(dense_output[2]>dense_output[pred]) pred = 2;
      if(pred == img.label) correct++;
    }
    
    update_weights(batch+1);
    
    running_loss += batch_loss / (batch_end - batch_start);
    loss_count++;
    
    if((batch+1) % 10 == 0) {
      float avg_loss = running_loss / loss_count;
      float acc = 100.0 * correct / (batch_end - batch_start);
      Serial.printf("Batch %d/%d - Loss: %.4f, Acc: %.1f%%\n", 
        batch+1, total_batches, avg_loss, acc);
      running_loss = 0;
      loss_count = 0;
    }
  }
  
  Serial.println("\n======== TRAINING COMPLETE ========");
}

// DEBUG OUTPUT
void print_debug() {
  Serial.println("\n========== DEBUG OUTPUT ==========");
  Serial.printf("Mode: %s %s\n", USE_GRAYSCALE_MODE?"GRAY":"RGB", USE_INT8_QUANTIZATION?"INT8":"FLOAT");
  Serial.printf("Classes: [%s, %s, %s]\n", class_labels[0].c_str(), class_labels[1].c_str(), class_labels[2].c_str());
  
  augment_image(training_data[0].data, input_buffer);
  forward_conv1();
  forward_pool1();
  forward_conv2();
  forward_dropout(false);
  forward_dense();
  
  Serial.println("\nLayer Stats:");
  
  auto print_stats = [](const char* name, float* buf, int len) {
    float mn=1e6, mx=-1e6, sum=0;
    int neg=0, zeros=0;
    for(int i=0; i<len; i++) {
      if(buf[i]<mn) mn=buf[i];
      if(buf[i]>mx) mx=buf[i];
      sum += buf[i];
      if(buf[i]<0) neg++;
      if(buf[i]==0) zeros++;
    }
    Serial.printf("  %s: Min=%.2f Max=%.2f Avg=%.2f Neg=%d%% Zeros=%d%%\n",
      name, mn, mx, sum/len, (neg*100)/len, (zeros*100)/len);
  };
  
  print_stats("CONV1", conv1_output, 15376);
  print_stats("POOL1", pool1_output, 3844);
  print_stats("CONV2", conv2_output, FLATTENED_SIZE);
  
  Serial.println("\nWeight Samples:");
  Serial.print("  Conv1_w[0-5]: ");
  for(int i=0; i<6; i++) { Serial.print(conv1_w[i],4); Serial.print(" "); }
  Serial.println();
  
  Serial.print("  Conv1_b[0-3]: ");
  for(int i=0; i<4; i++) { Serial.print(conv1_b[i],4); Serial.print(" "); }
  Serial.println();
  
  Serial.println("\nLogits:");
  for(int i=0; i<3; i++) {
    Serial.printf("  Class %d (%s): %.4f\n", i, class_labels[i].c_str(), 
      log(max(dense_output[i], 1e-7f)));
  }
  
  Serial.println("\nProbabilities:");
  Serial.printf("  [%.1f%%, %.1f%%, %.1f%%]\n", 
    dense_output[0]*100, dense_output[1]*100, dense_output[2]*100);
  
  Serial.println("===================================\n");
}

// SAVE MODEL HEADER (.h file for inference code)
bool save_model_header() {
  Serial.println("\n=== Saving Model Header ===");
  
  if(!SD.exists("/header")) {
    if(!SD.mkdir("/header")) {
      Serial.println("[ERR] Cannot create /header");
      return false;
    }
  }
  
  if(SD.exists("/header/myModel.h")) {
    SD.remove("/header/myModel.h");
    delay(100);
  }
  
  File file = SD.open("/header/myModel.h", FILE_WRITE);
  if(!file) {
    Serial.println("[ERR] Cannot open /header/myModel.h");
    return false;
  }
  
  file.println("// Auto-generated CNN model");
  file.println("#ifndef MY_MODEL_H");
  file.println("#define MY_MODEL_H");
  file.println();
  
  file.println("const char* myClassLabels[3] = {");
  file.print("  \""); file.print(toCString(class_labels[0])); file.println("\",");
  file.print("  \""); file.print(toCString(class_labels[1])); file.println("\",");
  file.print("  \""); file.print(toCString(class_labels[2])); file.println("\"");
  file.println("};");
  file.println();
  
  if(USE_INT8_QUANTIZATION) file.println("#define USE_INT8_MODE");
  if(USE_GRAYSCALE_MODE) file.println("#define USE_GRAYSCALE_MODE");
  file.println();
  
  int c1w_sz = USE_GRAYSCALE_MODE ? 36 : 108;
  
  if(USE_INT8_QUANTIZATION) {
    float mx=0;
    for(int i=0; i<c1w_sz; i++) if(abs(conv1_w[i])>mx) mx=abs(conv1_w[i]);
    float sc = 127.0/max(mx, 0.001f);
    file.print("const float myConv1_w_scale = "); file.print(sc,6); file.println("f;");
    file.print("const int8_t myConv1_w[] = { ");
    for(int i=0; i<c1w_sz; i++) {
      file.print((int8_t)round(conv1_w[i]*sc));
      if(i<c1w_sz-1) file.print(", ");
      if((i+1)%20==0) file.println();
    }
    file.println(" };");
  } else {
    file.print("const float myConv1_w[] = { ");
    for(int i=0; i<c1w_sz; i++) {
      file.print(conv1_w[i],6); file.print("f");
      if(i<c1w_sz-1) file.print(", ");
      if((i+1)%10==0) { file.println(); file.flush(); }
    }
    file.println(" };");
  }
  file.println();
  file.flush();
  
  if(USE_INT8_QUANTIZATION) {
    float mx=0;
    for(int i=0; i<4; i++) if(abs(conv1_b[i])>mx) mx=abs(conv1_b[i]);
    float sc = 127.0/max(mx, 0.001f);
    file.print("const float myConv1_b_scale = "); file.print(sc,6); file.println("f;");
    file.print("const int8_t myConv1_b[] = { ");
    for(int i=0; i<4; i++) {
      file.print((int8_t)round(conv1_b[i]*sc));
      if(i<3) file.print(", ");
    }
    file.println(" };");
  } else {
    file.print("const float myConv1_b[] = { ");
    for(int i=0; i<4; i++) {
      file.print(conv1_b[i],6); file.print("f");
      if(i<3) file.print(", ");
    }
    file.println(" };");
  }
  file.println();
  file.flush();
  
  if(USE_INT8_QUANTIZATION) {
    float mx=0;
    for(int i=0; i<288; i++) if(abs(conv2_w[i])>mx) mx=abs(conv2_w[i]);
    float sc = 127.0/max(mx, 0.001f);
    file.print("const float myConv2_w_scale = "); file.print(sc,6); file.println("f;");
    file.print("const int8_t myConv2_w[] = { ");
    for(int i=0; i<288; i++) {
      file.print((int8_t)round(conv2_w[i]*sc));
      if(i<287) file.print(", ");
      if((i+1)%20==0) { file.println(); file.flush(); }
    }
    file.println(" };");
  } else {
    file.print("const float myConv2_w[] = { ");
    for(int i=0; i<288; i++) {
      file.print(conv2_w[i],6); file.print("f");
      if(i<287) file.print(", ");
      if((i+1)%10==0) { file.println(); file.flush(); }
    }
    file.println(" };");
  }
  file.println();
  file.flush();
  
  if(USE_INT8_QUANTIZATION) {
    float mx=0;
    for(int i=0; i<8; i++) if(abs(conv2_b[i])>mx) mx=abs(conv2_b[i]);
    float sc = 127.0/max(mx, 0.001f);
    file.print("const float myConv2_b_scale = "); file.print(sc,6); file.println("f;");
    file.print("const int8_t myConv2_b[] = { ");
    for(int i=0; i<8; i++) {
      file.print((int8_t)round(conv2_b[i]*sc));
      if(i<7) file.print(", ");
    }
    file.println(" };");
  } else {
    file.print("const float myConv2_b[] = { ");
    for(int i=0; i<8; i++) {
      file.print(conv2_b[i],6); file.print("f");
      if(i<7) file.print(", ");
    }
    file.println(" };");
  }
  file.println();
  file.flush();
  
  Serial.println("Writing dense weights...");
  if(USE_INT8_QUANTIZATION) {
    float mx=0;
    for(int i=0; i<FLATTENED_SIZE*3; i++) if(abs(dense_w[i])>mx) mx=abs(dense_w[i]);
    float sc = 127.0/max(mx, 0.001f);
    file.print("const float myOutput_w_scale = "); file.print(sc,6); file.println("f;");
    file.print("const int8_t myOutput_w[] = { ");
    for(int i=0; i<FLATTENED_SIZE*3; i++) {
      file.print((int8_t)round(dense_w[i]*sc));
      if(i<FLATTENED_SIZE*3-1) file.print(", ");
      if((i+1)%50==0) { file.println(); file.flush(); }
    }
    file.println(" };");
  } else {
    file.print("const float myOutput_w[] = { ");
    for(int i=0; i<FLATTENED_SIZE*3; i++) {
      file.print(dense_w[i],6); file.print("f");
      if(i<FLATTENED_SIZE*3-1) file.print(", ");
      if((i+1)%20==0) { file.println(); file.flush(); }
      if((i+1)%500==0) Serial.printf("  %d/%d\n", i+1, FLATTENED_SIZE*3);
    }
    file.println(" };");
  }
  file.println();
  file.flush();
  
  if(USE_INT8_QUANTIZATION) {
    float mx=0;
    for(int i=0; i<3; i++) if(abs(dense_b[i])>mx) mx=abs(dense_b[i]);
    float sc = 127.0/max(mx, 0.001f);
    file.print("const float myOutput_b_scale = "); file.print(sc,6); file.println("f;");
    file.print("const int8_t myOutput_b[] = { ");
    for(int i=0; i<3; i++) {
      file.print((int8_t)round(dense_b[i]*sc));
      if(i<2) file.print(", ");
    }
    file.println(" };");
  } else {
    file.print("const float myOutput_b[] = { ");
    for(int i=0; i<3; i++) {
      file.print(dense_b[i],6); file.print("f");
      if(i<2) file.print(", ");
    }
    file.println(" };");
  }
  file.println();
  
  file.println("#endif");
  file.close();
  Serial.println("✓ Model header saved to /header/myModel.h");
  return true;
}

// SETUP
void setup() {
  Serial.begin(115200);
  pinMode(A0, INPUT);
  pinMode(LED_BUILTIN, OUTPUT);
  delay(2000);
  
  Serial.println("\n\nesp32-train BINARY CHECKPOINT version");
  Serial.println("=======================================");
  
  if(!SD.begin(21)) {
    Serial.println("[ERR] SD init failed");
    while(1) { delay(1000); }
  }
  Serial.println("SD card OK");
  
  load_images_from_sd();
  
  if(training_data.size() < 3) {
    Serial.println("[ERR] Need at least 3 images in /images/");
    while(1) { delay(1000); }
  }
  
  if(!allocate_model_memory()) {
    Serial.println("[ERR] Memory allocation failed");
    while(1) { delay(1000); }
  }
  
  // TRY TO LOAD CHECKPOINT
  weights_loaded_from_checkpoint = load_weights_from_binary();
  
  // If no checkpoint, initialize random
  if(!weights_loaded_from_checkpoint) {
    initialize_weights();
  }
  
  Serial.println("\n=== CONFIGURATION ===");
  Serial.printf("Mode: %s\n", USE_GRAYSCALE_MODE ? "GRAYSCALE" : "RGB");
  Serial.printf("Quantization: %s\n", USE_INT8_QUANTIZATION ? "INT8" : "FLOAT32");
  Serial.printf("Learning Rate: %.4f\n", LEARNING_RATE);
  Serial.printf("Dropout: %.2f\n", DROPOUT_RATE);
  Serial.printf("Batch Size: %d\n", BATCH_SIZE);
  Serial.printf("Epochs: %d\n", TARGET_EPOCHS);
  Serial.printf("Augmentation: %s\n", USE_AUGMENTATION ? "ON" : "OFF");
  Serial.printf("Training Images: %d [%d, %d, %d]\n", 
    training_data.size(), class_counts[0], class_counts[1], class_counts[2]);
  Serial.printf("Classes: [%s, %s, %s]\n", 
    class_labels[0].c_str(), class_labels[1].c_str(), class_labels[2].c_str());
  Serial.printf("Weights: %s\n", weights_loaded_from_checkpoint ? 
    "LOADED from checkpoint" : "RANDOM initialization");
  Serial.println("====================\n");
  Serial.println("Press A0 to train (continues from current weights)...");
}

// LOOP - NO WEIGHT INITIALIZATION, JUST TRAIN
void loop() {
  if(analogRead(A0) > 2000) {
    digitalWrite(LED_BUILTIN, LOW);
    Serial.println("\nA0 triggered - training from current weights...\n");
    
    // DO NOT call initialize_weights() here!
    // Weights are already loaded in setup() or will be random from setup()
    train_model();
    print_debug();
    
    // Save both binary checkpoint and .h header
    bool binary_ok = save_weights_to_binary();
    bool header_ok = save_model_header();
    
    if(binary_ok && header_ok) {
      Serial.println("\n✓ Training complete! Checkpoint & header saved!");
      Serial.println("  - /header/myWeights.bin (checkpoint for resume)");
      Serial.println("  - /header/myModel.h (C header for inference)");
      Serial.println("\nChange parameters and restart to continue training from checkpoint");
    } else {
      Serial.println("\n✗ Training complete but save failed!");
    }
    
    digitalWrite(LED_BUILTIN, HIGH);
    delay(2000);
    Serial.println("\nReady for next training (press A0)...\n");
  }
  
  delay(100);
}
