<!DOCTYPE html>
<html>
<head>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.22.0"></script>
</head>
<body style="font-family: sans-serif; background-color: #fdfdfd; padding: 10px;">

<h2 align="center">Rocksetta Pro: Fixed Export for ESP32</h2>

<div id="myCodeSpace"> 
  <div style="display: flex; gap: 15px; flex-wrap: wrap; justify-content: center; padding: 10px;">
    
    <div style="flex: 1; min-width: 350px; border: 1px solid #ccc; padding: 15px; background: white; border-radius: 10px;">
      <label style="font-weight: bold; color: darkblue; cursor: pointer; display: block; margin-bottom: 8px;">
        <input type="checkbox" id="myGrayscaleToggle" onchange="myCheckGrayscaleChange()"> Use Grayscale Mode
      </label>
      <p style="font-size: 11px; margin-top: -5px; color: #666;">(Set BEFORE starting - 3x smaller model)</p>
      <select id="myCameraSelect" style="width: 100%; margin-bottom: 5px;"></select>
      <div align="center">
          <video id="myVideo1" width="240" height="240" autoplay playsinline style="border: 2px solid black; background: #000; border-radius: 5px;"></video>
          <canvas id="myCanvas1" width="240" height="240" style="display:none; border: 2px solid black; border-radius: 5px;"></canvas>
      </div>
      <br>
      <div style="display: flex; gap: 5px;">
        <input type="button" id="myStartBtn" value="1. Start Camera & Brain" onclick="myStartAll()" style="flex: 1; font-weight:bold; padding:12px; background:#e1f5fe; border-radius: 5px; cursor:pointer;">
        <input type="button" id="myStopCameraBtn" value="â¹ Stop Camera" onclick="myStopCamera()" style="flex: 1; font-weight:bold; padding:12px; background:#ffcdd2; border-radius: 5px; cursor:pointer; display:none;">
      </div>
      <hr>
      <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 5px;">
        <span><b>Max Buffer:</b></span>
        <input type="number" id="myMaxBufferInput" value="100" min="10" max="500" style="width: 80px; padding: 2px;" onchange="myUpdateMaxBuffer()">
      </div>
      <hr>
      <div style="display: flex; justify-content: space-between;">
          <input type="button" value="Save TFJS" onclick="mySaveModel()" style="width:48%;">
          <input type="button" value="Load TFJS" onclick="myLoadModel()" style="width:48%;">
      </div>
      <hr>
      <b>Training:</b><br>
      <div style="display: flex; justify-content: space-between; margin-top:5px; text-align:center;">
        <div style="flex:1;">
          <input type="button" value="Train 0" onclick="myCollect(0)" style="width:90%; margin-bottom:3px;">
          <br><input type="button" value="Load" onclick="myLoadImages(0)" style="width:44%; font-size:10px; padding:3px;">
          <input type="button" value="Clear" onclick="myClearImages(0)" style="width:44%; font-size:10px; padding:3px; background:#ffebee;">
          <br><input type="button" value="Download" onclick="myDownloadImages(0)" style="width:90%; font-size:10px; padding:3px; background:#e3f2fd; margin-top:2px;">
          <br><input type="text" id="myLabel0" value="Class 0" size="8" style="margin-top:3px;">
          <br><span id="myCount0" style="font-size:11px; color:#666;">0 samples</span>
        </div>
        <div style="flex:1;">
          <input type="button" value="Train 1" onclick="myCollect(1)" style="width:90%; margin-bottom:3px;">
          <br><input type="button" value="Load" onclick="myLoadImages(1)" style="width:44%; font-size:10px; padding:3px;">
          <input type="button" value="Clear" onclick="myClearImages(1)" style="width:44%; font-size:10px; padding:3px; background:#ffebee;">
          <br><input type="button" value="Download" onclick="myDownloadImages(1)" style="width:90%; font-size:10px; padding:3px; background:#e3f2fd; margin-top:2px;">
          <br><input type="text" id="myLabel1" value="Class 1" size="8" style="margin-top:3px;">
          <br><span id="myCount1" style="font-size:11px; color:#666;">0 samples</span>
        </div>
        <div style="flex:1;">
          <input type="button" value="Train 2" onclick="myCollect(2)" style="width:90%; margin-bottom:3px;">
          <br><input type="button" value="Load" onclick="myLoadImages(2)" style="width:44%; font-size:10px; padding:3px;">
          <input type="button" value="Clear" onclick="myClearImages(2)" style="width:44%; font-size:10px; padding:3px; background:#ffebee;">
          <br><input type="button" value="Download" onclick="myDownloadImages(2)" style="width:90%; font-size:10px; padding:3px; background:#e3f2fd; margin-top:2px;">
          <br><input type="text" id="myLabel2" value="Class 2" size="8" style="margin-top:3px;">
          <br><span id="myCount2" style="font-size:11px; color:#666;">0 samples</span>
        </div>
      </div>
    </div>

    <div style="flex: 1; min-width: 350px; border: 2px solid green; padding: 15px; background: #f1f8e9; border-radius: 10px;">
      <b>2. Training Progress</b><hr>
      <div style="background: white; padding: 10px; border-radius: 5px; margin-bottom: 10px;">
        <div style="display: flex; justify-content: space-between; margin-bottom: 5px;">
          <span><b>Batches Trained:</b></span>
          <span id="myEpochDisplay" style="font-weight: bold; color: #2196F3;">0</span>
        </div>
        <div style="display: flex; justify-content: space-between; margin-bottom: 5px; align-items: center;">
          <span><b>Min Samples:</b></span>
          <input type="number" id="myMinSamples" value="10" min="1" max="100" style="width: 80px; padding: 2px;">
        </div>
        <div style="margin-bottom: 5px;">
          <label style="cursor: pointer;">
            <input type="checkbox" id="myUseAllData" checked onchange="myToggleEpochMode()"> Use All Data
          </label>
        </div>
        <div id="myEpochControls" style="display: block;">
          <div style="display: flex; justify-content: space-between; margin-bottom: 5px; align-items: center;">
            <span><b>Target Epochs:</b></span>
            <input type="number" id="myTargetEpochs" value="10" min="0" step="0.5" style="width: 80px; padding: 2px;">
          </div>
          <p id="myEpochHint" style="font-size: 11px; margin: -3px 0 5px 0; color: #666;"></p>
        </div>
        <div id="myBatchControls" style="display: none;">
          <div style="display: flex; justify-content: space-between; margin-bottom: 5px; align-items: center;">
            <span><b>Max Batches:</b></span>
            <input type="number" id="myMaxBatches" value="40" min="0" style="width: 80px; padding: 2px;">
          </div>
        </div>
        <div style="display: flex; justify-content: space-between; margin-bottom: 5px; align-items: center;">
          <span><b>Batch Size:</b></span>
          <input type="number" id="myBatchSize" value="6" min="3" max="30" step="3" style="width: 80px; padding: 2px;">
        </div>
        <div style="display: flex; justify-content: space-between; margin-bottom: 5px; align-items: center;">
          <span><b>Learning Rate:</b></span>
          <input type="number" id="myLearningRate" value="0.001" min="0.0001" max="0.1" step="0.0001" style="width: 80px; padding: 2px;">
        </div>
        <div style="display: flex; justify-content: space-between; margin-bottom: 5px; align-items: center;">
          <span><b>Dropout Rate:</b></span>
          <input type="number" id="myDropoutRate" value="0.3" min="0.0" max="0.9" step="0.1" style="width: 80px; padding: 2px;">
        </div>
        <div style="display: flex; justify-content: space-between; margin-bottom: 5px;">
          <span><b>Avg Loss:</b></span>
          <span id="myLossDisplay" style="font-weight: bold; color: #FF9800;">--</span>
        </div>
        <div style="display: flex; justify-content: space-between;">
          <span><b>Status:</b></span>
          <span id="myStatusDisplay" style="font-weight: bold; color: #9E9E9E;">Waiting...</span>
        </div>
        <div style="margin-top: 10px; display: flex; gap: 5px;">
          <input type="button" id="myPauseBtn" value="â¸ Pause" onclick="myPauseTraining()" style="flex: 1; padding: 8px; background: #FF9800; color: white; font-weight: bold; border-radius: 5px; cursor: pointer;" disabled>
          <input type="button" id="myResumeBtn" value="â–¶ Resume" onclick="myResumeTraining()" style="flex: 1; padding: 8px; background: #4CAF50; color: white; font-weight: bold; border-radius: 5px; cursor: pointer; display: none;">
        </div>
        <div style="margin-top: 10px; height: 8px; background: #e0e0e0; border-radius: 4px; overflow: hidden;">
          <div id="myProgressBar" style="width: 0%; height: 100%; background: linear-gradient(90deg, #4CAF50, #8BC34A); transition: width 0.3s;"></div>
        </div>
      </div>
      <hr>
      <b>Export (FIXED!)</b><br>
      <label style="font-weight: bold; color: darkgreen; cursor: pointer;">
        <input type="checkbox" id="myInt8Toggle"> Int8 Quantization
      </label>
      <p style="font-size: 11px;">(Saves memory on ESP32)</p>
      <input type="button" value="DOWNLOAD BINARY (.bin)" style="background-color:#2196F3; color:white; width:100%; padding:12px; font-weight:bold; border-radius: 5px; cursor:pointer; margin-bottom:10px;" onclick="myExportBinary()">
      <input type="button" value="DOWNLOAD HEADER (.h)" style="background-color:#4CAF50; color:white; width:100%; padding:12px; font-weight:bold; border-radius: 5px; cursor:pointer;" onclick="myExportHeader()">
      <hr>
      <input type="button" value="ðŸ” DEBUG Frame" style="background-color:#2196F3; color:white; width:100%; padding:10px; font-weight:bold; border-radius: 5px; cursor:pointer;" onclick="myDebugCurrentFrame()">
      <hr>
      <div style="margin-bottom: 10px; display: flex; gap: 5px;">
        <input type="button" id="myStopAnalysisBtn" value="â¹ Stop" onclick="myStopAnalysis()" style="flex: 1; padding: 8px; background: #F44336; color: white; font-weight: bold; border-radius: 5px; cursor: pointer;" disabled>
        <input type="button" id="myStartAnalysisBtn" value="â–¶ Start" onclick="myStartAnalysis()" style="flex: 1; padding: 8px; background: #2196F3; color: white; font-weight: bold; border-radius: 5px; cursor: pointer; display: none;">
      </div>
      <div id="myOutputDisplay" style="border: 1px solid green; padding: 10px; background: white; min-height: 50px;">Ready...</div>
    </div>

    <div style="flex: 1; min-width: 350px; border: 1px solid #ccc; padding: 15px; background: white; border-radius: 10px;">
      <b>3. Activity Logs</b><hr>
      <div id="myDivHistory" style="border: 1px solid blue; padding: 8px; height: 300px; overflow-y: scroll; font-family: monospace; font-size: 0.85em; background: #f1f8ff; border-radius: 5px;">
        Logs will appear here...
      </div>
    </div>
  </div>

  <script>
    var myModel, myTimer;
    var myTrainData = {0:[], 1:[], 2:[]};
    var myMaxBuffer = 100;
    var myEpochCount = 0;
    var myLossHistory = [];
    var myLossSum = 0;
    var myLossCount = 0;
    var myTrainingPaused = false;
    var myAnalysisStopped = false;
    var myIsGrayscaleMode = false;
    var myGrayscaleRenderTimer = null;
    var myAllDataIndex = 0;
    var myCurrentEpoch = 0;
    var myShuffledData = [];
    var myCameraStopped = false;

    function myLog(myMsg) {
        const myDiv = document.getElementById('myDivHistory');
        const myTime = new Date().toLocaleTimeString();
        myDiv.innerHTML = `[${myTime}] ${myMsg}<br>` + myDiv.innerHTML;
    }

    function myUpdateMaxBuffer() {
      myMaxBuffer = parseInt(document.getElementById('myMaxBufferInput').value) || 100;
      myLog(`Max buffer: ${myMaxBuffer} samples/class`);
    }

    function myToggleEpochMode() {
      const useAllData = document.getElementById('myUseAllData').checked;
      document.getElementById('myEpochControls').style.display = useAllData ? 'block' : 'none';
      document.getElementById('myBatchControls').style.display = useAllData ? 'none' : 'block';
      myUpdateEpochHint();
    }

    function myUpdateEpochHint() {
      if (!document.getElementById('myUseAllData').checked) return;
      const counts = [myTrainData[0].length, myTrainData[1].length, myTrainData[2].length];
      const totalSamples = counts[0] + counts[1] + counts[2];
      const batchSize = parseInt(document.getElementById('myBatchSize').value) || 6;
      const batchesPerEpoch = Math.ceil(totalSamples / batchSize);
      const targetEpochs = parseFloat(document.getElementById('myTargetEpochs').value) || 10;
      const totalBatches = Math.ceil(targetEpochs * batchesPerEpoch);
      const hintElement = document.getElementById('myEpochHint');
      if (hintElement) {
        if (totalSamples > 0) {
          hintElement.innerText = `(â‰ˆ ${batchesPerEpoch} batches/epoch = ${totalBatches} total)`;
        } else {
          hintElement.innerText = '(Waiting for data...)';
        }
      }
    }

    function myAugment(tensor) {
      return tf.tidy(() => {
        let augmented = tensor;
        if (Math.random() > 0.5) {
          const brightness = (Math.random() - 0.5) * 0.2;
          augmented = augmented.add(brightness).clipByValue(0, 1);
        }
        if (Math.random() > 0.5) {
          const contrast = 0.8 + Math.random() * 0.4;
          const mean = augmented.mean();
          augmented = augmented.sub(mean).mul(contrast).add(mean).clipByValue(0, 1);
        }
        return augmented;
      });
    }

    function myStopAnalysis() {
      myAnalysisStopped = true;
      document.getElementById('myStopAnalysisBtn').style.display = 'none';
      document.getElementById('myStartAnalysisBtn').style.display = 'block';
      document.getElementById('myOutputDisplay').innerHTML = '<span style="color:#666;">Analysis Stopped</span>';
      myLog("Analysis Stopped");
    }

    function myStartAnalysis() {
      myAnalysisStopped = false;
      document.getElementById('myStopAnalysisBtn').style.display = 'block';
      document.getElementById('myStartAnalysisBtn').style.display = 'none';
      myLog("Analysis Started");
    }

    function myStopCamera() {
      const myVideo = document.getElementById('myVideo1');
      if (myVideo.srcObject) {
        myVideo.srcObject.getTracks().forEach(track => track.stop());
        myVideo.srcObject = null;
      }
      if (myGrayscaleRenderTimer) {
        clearInterval(myGrayscaleRenderTimer);
        myGrayscaleRenderTimer = null;
      }
      myCameraStopped = true;
      document.getElementById('myStartBtn').style.display = 'block';
      document.getElementById('myStopCameraBtn').style.display = 'none';
      myLog("Camera Stopped");
    }

    function myCheckGrayscaleChange() {
      if (myModel) {
        alert('âš ï¸ Changing color mode requires restart.\n\nRefresh page to switch modes.');
        document.getElementById('myGrayscaleToggle').checked = myIsGrayscaleMode;
      }
    }

    async function myStartAll() {
      const myVideo = document.getElementById('myVideo1');
      const myCanvas = document.getElementById('myCanvas1');
      const myCtx = myCanvas.getContext('2d');
      
      if (!myVideo.srcObject) {
        myCameraStopped = false;
        const myDeviceId = document.getElementById('myCameraSelect').value;
        myVideo.srcObject = await navigator.mediaDevices.getUserMedia({
          video: { width: 240, height: 240, deviceId: myDeviceId ? { exact: myDeviceId } : undefined }
        });
        myLog("Camera Started");
        document.getElementById('myStartBtn').style.display = 'none';
        document.getElementById('myStopCameraBtn').style.display = 'block';
        
        myIsGrayscaleMode = document.getElementById('myGrayscaleToggle').checked;
        if (myIsGrayscaleMode) {
          myVideo.style.display = 'none';
          myCanvas.style.display = 'block';
          if (myGrayscaleRenderTimer) clearInterval(myGrayscaleRenderTimer);
          myGrayscaleRenderTimer = setInterval(() => {
            myCtx.drawImage(myVideo, 0, 0, 240, 240);
            const myImageData = myCtx.getImageData(0, 0, 240, 240);
            const myData = myImageData.data;
            for (let i = 0; i < myData.length; i += 4) {
              const myGray = myData[i] * 0.299 + myData[i+1] * 0.587 + myData[i+2] * 0.114;
              myData[i] = myGray; myData[i+1] = myGray; myData[i+2] = myGray;
            }
            myCtx.putImageData(myImageData, 0, 0);
          }, 33);
        } else {
          myVideo.style.display = 'block';
          myCanvas.style.display = 'none';
        }
      }
      
      if (!myModel) {
        const inputChannels = myIsGrayscaleMode ? 1 : 3;
        const lr = parseFloat(document.getElementById('myLearningRate').value) || 0.001;
        const dropout = parseFloat(document.getElementById('myDropoutRate').value) || 0.3;
        
        myModel = tf.sequential();
        myModel.add(tf.layers.conv2d({
          inputShape:[64,64,inputChannels], 
          kernelSize:3, 
          filters:4, 
          activation: null,
          kernelRegularizer: tf.regularizers.l2({l2: 0.0001}), 
          biasInitializer: 'zeros'
        }));
        myModel.add(tf.layers.leakyReLU({alpha: 0.1}));
        myModel.add(tf.layers.maxPooling2d({poolSize:2, strides:2}));
        
        myModel.add(tf.layers.conv2d({
          kernelSize:3, 
          filters:8, 
          activation: null,
          kernelRegularizer: tf.regularizers.l2({l2: 0.0001}), 
          biasInitializer: 'zeros'
        }));
        myModel.add(tf.layers.leakyReLU({alpha: 0.1}));
        myModel.add(tf.layers.flatten());
        myModel.add(tf.layers.dropout({rate: dropout}));
        myModel.add(tf.layers.dense({
          units:3, 
          activation:'softmax', 
          kernelInitializer: 'heNormal', 
          biasInitializer: 'zeros'
        }));
        
        myModel.compile({
          optimizer: tf.train.adam(lr), 
          loss:'categoricalCrossentropy', 
          metrics: ['accuracy']
        });
        
        myLog(`Model: ${myIsGrayscaleMode ? 'Gray' : 'RGB'}, LR:${lr}, Dropout:${dropout}`);
      }
      
      if (myTimer) clearInterval(myTimer);
      myTimer = setInterval(async () => {
        let myInput = null;
        if (!myCameraStopped && myVideo.srcObject) {
          myInput = tf.browser.fromPixels(myVideo).resizeBilinear([64,64]);
          if (myIsGrayscaleMode) {
            const old = myInput;
            myInput = tf.tidy(() => {
              const r = old.slice([0,0,0], [64,64,1]);
              const g = old.slice([0,0,1], [64,64,1]);
              const b = old.slice([0,0,2], [64,64,1]);
              return r.mul(0.299).add(g.mul(0.587)).add(b.mul(0.114));
            });
            old.dispose();
          }
          const old2 = myInput;
          myInput = myInput.div(255.0).expandDims(0);
          old2.dispose();
        }
        
        // Training
        const minSamples = parseInt(document.getElementById('myMinSamples').value) || 10;
        const counts = [myTrainData[0].length, myTrainData[1].length, myTrainData[2].length];
        const minCount = Math.min(...counts);
        let batchSize = parseInt(document.getElementById('myBatchSize').value) || 6;
        if (batchSize < 3) batchSize = 3;
        if (batchSize % 3 !== 0) batchSize = Math.ceil(batchSize / 3) * 3;
        
        const useAllData = document.getElementById('myUseAllData').checked;
        let maxBatches = 0;
        if (useAllData) {
          const targetEpochs = parseFloat(document.getElementById('myTargetEpochs').value) || 0;
          const totalSamples = counts[0] + counts[1] + counts[2];
          const batchesPerEpoch = totalSamples > 0 ? Math.ceil(totalSamples / batchSize) : 1;
          maxBatches = targetEpochs > 0 ? Math.ceil(targetEpochs * batchesPerEpoch) : 0;
        } else {
          maxBatches = parseInt(document.getElementById('myMaxBatches').value) || 0;
        }
        
        const reachedLimit = maxBatches > 0 && myEpochCount >= maxBatches;
        
        if (minCount >= minSamples && !myTrainingPaused && !reachedLimit) {
          let batch = [], labels = [];
          
          if (useAllData) {
            if (myAllDataIndex === 0) {
              myCurrentEpoch++; myShuffledData = [];
              for (let cls = 0; cls < 3; cls++) {
                for (let i = 0; i < myTrainData[cls].length; i++) {
                  myShuffledData.push({sample: myTrainData[cls][i], label: cls});
                }
              }
              for (let i = myShuffledData.length - 1; i > 0; i--) {
                const j = Math.floor(Math.random() * (i + 1));
                [myShuffledData[i], myShuffledData[j]] = [myShuffledData[j], myShuffledData[i]];
              }
              myLog(`Epoch ${myCurrentEpoch} (${myShuffledData.length} samples)`);
            }
            for (let i = 0; i < batchSize && myAllDataIndex < myShuffledData.length; i++) {
              const item = myShuffledData[myAllDataIndex];
              const aug = (Math.random() > 0.5) ? myAugment(item.sample) : tf.clone(item.sample);
              batch.push(aug);
              labels.push(item.label === 0 ? [1,0,0] : item.label === 1 ? [0,1,0] : [0,0,1]);
              myAllDataIndex++;
            }
            if (myAllDataIndex >= myShuffledData.length) myAllDataIndex = 0;
          } else {
            const samplesPerClass = batchSize / 3;
            for (let cls = 0; cls < 3; cls++) {
              for (let i = 0; i < samplesPerClass; i++) {
                const idx = Math.floor(Math.random() * myTrainData[cls].length);
                const aug = (Math.random() > 0.5) ? myAugment(myTrainData[cls][idx]) : tf.clone(myTrainData[cls][idx]);
                batch.push(aug);
                labels.push(cls === 0 ? [1,0,0] : cls === 1 ? [0,1,0] : [0,0,1]);
              }
            }
          }
          
          const batchTensor = tf.concat(batch);
          const labelsTensor = tf.tensor2d(labels);
          let currentLoss = 0;
          
          try {
            const result = await myModel.trainOnBatch(batchTensor, labelsTensor);
            currentLoss = Array.isArray(result) ? result[0] : result;
            if (isNaN(currentLoss) || !isFinite(currentLoss)) currentLoss = 0;
          } catch (error) {
            myLog("ERROR: " + error.message);
          }
          
          batchTensor.dispose(); 
          labelsTensor.dispose();
          batch.forEach(t => {
            let stored = false;
            for (let cls = 0; cls < 3; cls++) {
              if (myTrainData[cls].includes(t)) { stored = true; break; }
            }
            if (!stored) t.dispose();
          });
          
          myEpochCount++;
          if (currentLoss > 0) { myLossSum += currentLoss; myLossCount++; }
          
          if (myEpochCount % 10 === 0) {
            const avgLoss = myLossCount > 0 ? myLossSum / myLossCount : 0;
            if (avgLoss > 0 && isFinite(avgLoss)) myLossHistory.push(avgLoss);
            if (myLossHistory.length > 20) myLossHistory.shift();
            
            const recent = myLossHistory.length > 0 ? myLossHistory.reduce((a,b) => a+b, 0) / myLossHistory.length : 0;
            document.getElementById('myEpochDisplay').innerText = myEpochCount;
            document.getElementById('myLossDisplay').innerText = myLossHistory.length > 0 ? recent.toFixed(4) : '--';
            
            let status, color, progress;
            if (myLossHistory.length === 0) { status = 'Init...'; color = '#9E9E9E'; progress = 5; }
            else if (recent > 1.0) { status = 'Starting...'; color = '#FF5722'; progress = 10; }
            else if (recent > 0.5) { status = 'Training...'; color = '#FF9800'; progress = 30; }
            else if (recent > 0.2) { status = 'Improving...'; color = '#FFC107'; progress = 60; }
            else if (recent > 0.1) { status = 'Converging...'; color = '#8BC34A'; progress = 80; }
            else { status = 'Well Trained âœ“'; color = '#4CAF50'; progress = 100; }
            
            document.getElementById('myStatusDisplay').innerText = status;
            document.getElementById('myStatusDisplay').style.color = color;
            document.getElementById('myProgressBar').style.width = progress + '%';
            document.getElementById('myPauseBtn').disabled = false;
            myLossSum = 0; myLossCount = 0;
          }
        }
        
        // Prediction
        if (myInput && !myAnalysisStopped) {
          document.getElementById('myStopAnalysisBtn').disabled = false;
          const pred = myModel.predict(myInput);
          const probs = await pred.data();
          const id = (await pred.argMax(1).data())[0];
          const conf0 = (probs[0] * 100).toFixed(1);
          const conf1 = (probs[1] * 100).toFixed(1);
          const conf2 = (probs[2] * 100).toFixed(1);
          const maxConf = Math.max(probs[0], probs[1], probs[2]) * 100;
          const color = maxConf > 80 ? 'green' : maxConf > 50 ? 'orange' : 'red';
          
          document.getElementById('myOutputDisplay').innerHTML = 
            `<div style="font-weight:bold; font-size:1.1em; margin-bottom:8px;">` +
            `DETECTED: <span style="color:${color}">${document.getElementById('myLabel'+id).value}</span></div>` +
            `<div style="font-family:monospace; font-size:0.9em;">` +
            `${document.getElementById('myLabel0').value}: <b>${conf0}%</b><br>` +
            `${document.getElementById('myLabel1').value}: <b>${conf1}%</b><br>` +
            `${document.getElementById('myLabel2').value}: <b>${conf2}%</b></div>`;
          
          pred.dispose();
        }
        
        if (myInput) myInput.dispose();
      }, 150);
    }

    function myPauseTraining() {
      myTrainingPaused = true;
      document.getElementById('myPauseBtn').style.display = 'none';
      document.getElementById('myResumeBtn').style.display = 'block';
      myLog("Training Paused");
    }

    function myResumeTraining() {
      myTrainingPaused = false;
      document.getElementById('myPauseBtn').style.display = 'block';
      document.getElementById('myResumeBtn').style.display = 'none';
      myLog("Training Resumed");
    }

    async function myDebugCurrentFrame() {
      if (!myModel || !document.getElementById('myVideo1').srcObject) {
        myLog("ERROR: Start camera first!");
        return;
      }
      
      myLog("========== DEBUG ==========");
      myLog(`Mode: ${myIsGrayscaleMode ? 'GRAY' : 'RGB'} FLOAT32`);
      myLog(`Layers: ${myModel.layers.map((l,i) => `${i}:${l.name}`).join(', ')}`);
      
      const c1w = await myModel.layers[0].getWeights()[0].data();
      const c1b = await myModel.layers[0].getWeights()[1].data();
      
      myLog(`Conv1_w[0-5]: ${Array.from(c1w.slice(0, 6)).map(v => v.toFixed(4)).join(' ')}`);
      myLog(`Conv1_b[0-3]: ${Array.from(c1b.slice(0, 4)).map(v => v.toFixed(4)).join(' ')}`);
      myLog("========== END DEBUG ==========");
    }

    function myCollect(id) {
      const video = document.getElementById('myVideo1');
      if (!video.srcObject || myCameraStopped) { myLog("ERROR: Camera not running!"); return; }
      
      let frame = tf.browser.fromPixels(video).resizeBilinear([64,64]);
      if (myIsGrayscaleMode) {
        const old = frame;
        frame = tf.tidy(() => {
          const r = old.slice([0,0,0], [64,64,1]);
          const g = old.slice([0,0,1], [64,64,1]);
          const b = old.slice([0,0,2], [64,64,1]);
          return r.mul(0.299).add(g.mul(0.587)).add(b.mul(0.114));
        });
        old.dispose();
      }
      const old2 = frame;
      frame = frame.div(255.0).expandDims(0);
      old2.dispose();
      
      if (myTrainData[id].length < myMaxBuffer) {
        myTrainData[id].push(frame);
      } else {
        myTrainData[id][0].dispose();
        myTrainData[id].shift();
        myTrainData[id].push(frame);
      }
      
      document.getElementById('myCount' + id).innerHTML = `${myTrainData[id].length} samples`;
      myLog(`Class ${id} captured (${myTrainData[id].length} total)`);
      myUpdateEpochHint();
    }

    function myLoadImages(id) {
      const input = document.createElement('input');
      input.type = 'file'; input.multiple = true; input.accept = 'image/*';
      input.onchange = async (e) => {
        const files = Array.from(e.target.files);
        myLog(`Loading ${files.length} images for Class ${id}...`);
        let loaded = 0;
        
        for (const file of files) {
          try {
            const img = new Image();
            const url = URL.createObjectURL(file);
            await new Promise((resolve, reject) => {
              img.onload = () => {
                try {
                  let tensor = tf.browser.fromPixels(img).resizeBilinear([64,64]);
                  if (myIsGrayscaleMode) {
                    const old = tensor;
                    tensor = tf.tidy(() => {
                      const r = old.slice([0,0,0], [64,64,1]);
                      const g = old.slice([0,0,1], [64,64,1]);
                      const b = old.slice([0,0,2], [64,64,1]);
                      return r.mul(0.299).add(g.mul(0.587)).add(b.mul(0.114));
                    });
                    old.dispose();
                  }
                  const old2 = tensor;
                  tensor = tensor.div(255.0).expandDims(0);
                  old2.dispose();
                  
                  if (myTrainData[id].length < myMaxBuffer) {
                    myTrainData[id].push(tensor);
                  } else {
                    myTrainData[id][0].dispose();
                    myTrainData[id].shift();
                    myTrainData[id].push(tensor);
                  }
                  loaded++;
                  URL.revokeObjectURL(url);
                  resolve();
                } catch (err) { URL.revokeObjectURL(url); reject(err); }
              };
              img.onerror = () => { URL.revokeObjectURL(url); reject(new Error('Failed')); };
              img.src = url;
            });
          } catch (err) { console.error('Error:', err); }
        }
        
        document.getElementById('myCount' + id).innerHTML = `${myTrainData[id].length} samples`;
        myLog(`Class ${id}: Loaded ${loaded}/${files.length} (total: ${myTrainData[id].length})`);
        myUpdateEpochHint();
      };
      input.click();
    }

    function myClearImages(id) {
      if (myTrainData[id].length === 0) { myLog(`Class ${id}: Already empty`); return; }
      const count = myTrainData[id].length;
      myTrainData[id].forEach(t => t.dispose());
      myTrainData[id] = [];
      document.getElementById('myCount' + id).innerHTML = `0 samples`;
      myLog(`Class ${id}: Cleared ${count} samples`);
      myUpdateEpochHint();
    }

    async function myDownloadImages(id) {
      if (myTrainData[id].length === 0) {
        myLog(`Class ${id}: No images to download`);
        return;
      }
      
      const className = document.getElementById('myLabel' + id).value.replace(/[^a-zA-Z0-9]/g, '_');
      myLog(`Downloading ${myTrainData[id].length} images for ${className}...`);
      
      const canvas = document.createElement('canvas');
      canvas.width = 64;
      canvas.height = 64;
      
      for (let i = 0; i < myTrainData[id].length; i++) {
        const tensor = myTrainData[id][i];
        const squeezed = tensor.squeeze();
        
        await tf.browser.toPixels(squeezed, canvas);
        
        await new Promise((resolve) => {
          canvas.toBlob((blob) => {
            const link = document.createElement('a');
            link.href = URL.createObjectURL(blob);
            link.download = `${className}_${String(i+1).padStart(4, '0')}.jpg`;
            link.click();
            URL.revokeObjectURL(link.href);
            setTimeout(resolve, 100);
          }, 'image/jpeg', 0.95);
        });
      }
      
      myLog(`âœ“ Downloaded ${myTrainData[id].length} as ${className}_####.jpg`);
    }

    // FIXED BINARY EXPORT
    async function myExportBinary() {
      if (!myModel) { alert('No model!'); return; }
      
      console.log('=== BINARY EXPORT ===');
      const c1w = await myModel.layers[0].getWeights()[0].data();
      const c1b = await myModel.layers[0].getWeights()[1].data();
      const c2w = await myModel.layers[3].getWeights()[0].data();
      const c2b = await myModel.layers[3].getWeights()[1].data();
      const dw = await myModel.layers[7].getWeights()[0].data();
      const db = await myModel.layers[7].getWeights()[1].data();
      
      console.log('Sizes:', c1w.length, c1b.length, c2w.length, c2b.length, dw.length, db.length);
      
      const total = c1w.length + c1b.length + c2w.length + c2b.length + dw.length + db.length;
      const buffer = new Float32Array(total);
      
      let offset = 0;
      buffer.set(c1w, offset); offset += c1w.length;
      buffer.set(c1b, offset); offset += c1b.length;
      buffer.set(c2w, offset); offset += c2w.length;
      buffer.set(c2b, offset); offset += c2b.length;
      buffer.set(dw, offset); offset += dw.length;
      buffer.set(db, offset);
      
      const blob = new Blob([buffer], {type: 'application/octet-stream'});
      const link = document.createElement('a');
      link.href = URL.createObjectURL(blob);
      link.download = 'myWeights.bin';
      link.click();
      
      myLog(`âœ“ Binary exported (${total} floats, ${total*4} bytes)`);
    }

    // FIXED HEADER EXPORT
    async function myExportHeader() {
      if (!myModel) { alert('No model!'); return; }
      
      const isInt8 = document.getElementById('myInt8Toggle').checked;
      const l0 = document.getElementById('myLabel0').value.substring(0,20);
      const l1 = document.getElementById('myLabel1').value.substring(0,20);
      const l2 = document.getElementById('myLabel2').value.substring(0,20);
      
      let text = `// Auto-generated\n#ifndef MY_MODEL_H\n#define MY_MODEL_H\n\n`;
      text += `const char* myClassLabels[3] = {\n  "${l0}",\n  "${l1}",\n  "${l2}"\n};\n\n`;
      
      if (isInt8) text += `#define USE_INT8_MODE\n`;
      if (myIsGrayscaleMode) text += `#define USE_GRAYSCALE_MODE\n`;
      text += `\n`;
      
      const weights = [
        {name: 'myConv1_w', data: await myModel.layers[0].getWeights()[0].data()},
        {name: 'myConv1_b', data: await myModel.layers[0].getWeights()[1].data()},
        {name: 'myConv2_w', data: await myModel.layers[3].getWeights()[0].data()},
        {name: 'myConv2_b', data: await myModel.layers[3].getWeights()[1].data()},
        {name: 'myOutput_w', data: await myModel.layers[7].getWeights()[0].data()},
        {name: 'myOutput_b', data: await myModel.layers[7].getWeights()[1].data()}
      ];
      
      for (const {name, data} of weights) {
        const arr = Array.from(data);
        
        if (isInt8) {
          const maxAbs = Math.max(...arr.map(Math.abs));
          const scale = 127.0 / (maxAbs || 1);
          text += `const float ${name}_scale = ${scale.toFixed(6)}f;\n`;
          text += `const int8_t ${name}[] = { `;
          text += arr.map(v => Math.round(v * scale)).join(', ');
          text += ` };\n\n`;
        } else {
          text += `const float ${name}[] = { `;
          text += arr.map(v => v.toFixed(6) + 'f').join(', ');
          text += ` };\n\n`;
        }
      }
      
      text += `#endif`;
      
      const blob = new Blob([text], {type: 'text/plain'});
      const link = document.createElement('a');
      link.href = URL.createObjectURL(blob);
      link.download = 'myModel.h';
      link.click();
      
      myLog(`âœ“ Header exported`);
    }

    async function mySaveModel() { 
      await myModel.save('downloads://my-tfjs-model'); 
      myLog("TFJS saved"); 
    }
    
    async function myLoadModel() {
      const input = document.createElement('input');
      input.type = 'file';
      input.multiple = true;
      input.onchange = async (e) => { 
        myModel = await tf.loadLayersModel(tf.io.browserFiles(e.target.files)); 
        myLog("TFJS loaded"); 
      };
      input.click();
    }

    // Init camera list
    (async function init() {
      const devices = await navigator.mediaDevices.enumerateDevices();
      const select = document.getElementById('myCameraSelect');
      devices.filter(d => d.kind === 'videoinput').forEach((d, i) => {
        const opt = document.createElement('option');
        opt.value = d.deviceId;
        opt.text = d.label || `Camera ${i + 1}`;
        select.appendChild(opt);
      });
    })();
  </script>
</div>

<div align="center">
  <input id="myUpdateBtn" type="button" value="Update & Run Code" style="visibility:hidden; background-color: yellow; font-weight:bold; padding:12px; border-radius:8px; cursor:pointer;" onclick="myApplyAndRun()">
</div>

<textarea id="myTextarea1" wrap="off" rows="2" style="width:95%; background:black; color:white; font-family:monospace; margin:15px; padding:10px; border-radius:10px;" onclick="myToggleEditor()">
Click here to see/edit the Source Code...
</textarea>

<script>
let myOnce = true;
function myToggleEditor() {
    if (myOnce) {
       myTextGrow('myTextarea1', 'myCodeSpace');
       document.getElementById('myUpdateBtn').style.visibility = 'visible';
       myOnce = false;
    }
}
function myApplyAndRun() {
  let myLines = document.getElementById('myTextarea1').value.split('\n');
  myLines.shift(); myLines.shift(); myLines.pop();   
  document.getElementById('myCodeSpace').innerHTML = myLines.join('\n');
  location.reload();
}
function myTextGrow(myT, myC) {
   const myArea = document.getElementById(myT);
   myArea.value = '\x3Cscript src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.22.0">\x3C/script>\n\n' + document.getElementById(myC).innerHTML;
   myArea.rows = 20;
}
</script>









  <br>  <br>
  <h2>XIAO ML Kit Code below</h2>
You will need to export the header file and enter it as myModel.h as an include file with the code below <br>

<textarea rows=30 cols="200" nowrap>

#include "esp_camera.h"
#include "img_converters.h"
#include "myModel.h" 

// --- 1. CONFIGURATION & BUFFERS ---
#ifdef USE_GRAYSCALE_MODE
  float myInputBuffer[64 * 64 * 1];  
#else
  float myInputBuffer[64 * 64 * 3];  
#endif

float myConv1Output[62 * 62 * 4];
float myPool1Output[31 * 31 * 4];
float myConv2Output[29 * 29 * 8];

inline float clipValue(float val, float minVal = -100.0f, float maxVal = 100.0f) {
    if (isnan(val) || isinf(val)) return 0.0f;
    if (val < minVal) return minVal;
    if (val > maxVal) return maxVal;
    return val;
}

#ifdef USE_INT8_MODE
  #define GET_W(arr, idx, scale) ((float)arr[idx] / scale)
#else
  #define GET_W(arr, idx, scale) (arr[idx])
  float myConv1_w_scale=1, myConv1_b_scale=1;
  float myConv2_w_scale=1, myConv2_b_scale=1;
  float myOutput_w_scale=1, myOutput_b_scale=1;
#endif

// Camera Pins
#define XCLK_GPIO_NUM 10
#define SIOD_GPIO_NUM 40
#define SIOC_GPIO_NUM 39
#define Y9_GPIO_NUM   48
#define Y8_GPIO_NUM   11
#define Y7_GPIO_NUM   12
#define Y6_GPIO_NUM   14
#define Y5_GPIO_NUM   16
#define Y4_GPIO_NUM   18
#define Y3_GPIO_NUM   17
#define Y2_GPIO_NUM   15
#define VSYNC_GPIO_NUM 38
#define HREF_GPIO_NUM  47
#define PCLK_GPIO_NUM  13

// --- 2. LAYERS ---
void myConv1() {
    for (int f = 0; f < 4; f++) {
        int outBase = f * 3844;
        for (int y = 0; y < 62; y++) {
            for (int x = 0; x < 62; x++) {
                float sum = 0;
                #ifdef USE_GRAYSCALE_MODE
                  for (int ky = 0; ky < 3; ky++) {
                      for (int kx = 0; kx < 3; kx++) {
                          int pIdx = (y+ky)*64 + (x+kx);
                          int wIdx = (f*9) + (ky*3) + kx;
                          sum += myInputBuffer[pIdx] * GET_W(myConv1_w, wIdx, myConv1_w_scale);
                      }
                  }
                #else
                  for (int ky = 0; ky < 3; ky++) {
                      for (int kx = 0; kx < 3; kx++) {
                          int pIdx = ((y+ky)*64 + (x+kx))*3;
                          int wIdx = (f*27) + (ky*9) + (kx*3);
                          sum += myInputBuffer[pIdx]   * GET_W(myConv1_w, wIdx,   myConv1_w_scale);
                          sum += myInputBuffer[pIdx+1] * GET_W(myConv1_w, wIdx+1, myConv1_w_scale);
                          sum += myInputBuffer[pIdx+2] * GET_W(myConv1_w, wIdx+2, myConv1_w_scale);
                      }
                  }
                #endif
                sum += GET_W(myConv1_b, f, myConv1_b_scale);
                sum = clipValue(sum, -100.0f, 100.0f);
                // Changed from ReLU to LeakyReLU to prevent dying neurons
                // Debug showed 50% zeros in CONV1 for grayscale, 22% for RGB
                // LeakyReLU allows small negative values: f(x) = x if x>0, else 0.1*x
                myConv1Output[outBase + (y*62 + x)] = (sum > 0) ? sum : (0.1f * sum);
            }
        }
    }
}

void myMaxPool1() {
    for (int f = 0; f < 4; f++) {
        int inBase = f * 3844;
        int outBase = f * 961;
        for (int y = 0; y < 31; y++) {
            for (int x = 0; x < 31; x++) {
                int inY = y * 2; int inX = x * 2;
                float maxVal = myConv1Output[inBase + (inY*62 + inX)];
                maxVal = max(maxVal, myConv1Output[inBase + (inY*62 + inX+1)]);
                maxVal = max(maxVal, myConv1Output[inBase + ((inY+1)*62 + inX)]);
                maxVal = max(maxVal, myConv1Output[inBase + ((inY+1)*62 + inX+1)]);
                myPool1Output[outBase + (y*31 + x)] = maxVal;
            }
        }
    }
}

void myConv2() {
    for (int f = 0; f < 8; f++) {
        int outBase = f * 841;
        for (int y = 0; y < 29; y++) {
            for (int x = 0; x < 29; x++) {
                float sum = 0;
                for (int c = 0; c < 4; c++) {
                    int inBase = c * 961;
                    for (int ky = 0; ky < 3; ky++) {
                        for (int kx = 0; kx < 3; kx++) {
                            int pIdx = inBase + ((y+ky)*31 + (x+kx));
                            int wIdx = (f*36) + (c*9) + (ky*3) + kx;
                            sum += myPool1Output[pIdx] * GET_W(myConv2_w, wIdx, myConv2_w_scale);
                        }
                    }
                }
                sum += GET_W(myConv2_b, f, myConv2_b_scale);
                sum = clipValue(sum, -100.0f, 100.0f);
                // Changed from ReLU to LeakyReLU to prevent dying neurons
                // Debug showed 84% zeros in CONV2 for grayscale models
                // LeakyReLU allows small negative values: f(x) = x if x>0, else 0.1*x
                myConv2Output[outBase + (y*29 + x)] = (sum > 0) ? sum : (0.1f * sum);
            }
        }
    }
}

int myGetWinner() {
    float myLogits[3] = {0, 0, 0};
    int totalFeatures = 29 * 29 * 8;
    for (int i = 0; i < 3; i++) {
        double sum = 0.0; double compensation = 0.0;
        for (int j = 0; j < totalFeatures; j++) {
            double term = (double)myConv2Output[j] * GET_W(myOutput_w, i*totalFeatures + j, myOutput_w_scale);
            double y = term - compensation; double t = sum + y;
            compensation = (t - sum) - y; sum = t;
        }
        myLogits[i] = clipValue((float)sum + GET_W(myOutput_b, i, myOutput_b_scale), -50.0f, 50.0f);
    }
    
    float maxLogit = max(max(myLogits[0], myLogits[1]), myLogits[2]);
    float expSum = exp(myLogits[0]-maxLogit) + exp(myLogits[1]-maxLogit) + exp(myLogits[2]-maxLogit);
    Serial.print("Probs: [");
    for (int i = 0; i < 3; i++) {
        float p = exp(myLogits[i]-maxLogit) / expSum * 100.0f;
        Serial.print(p, 0); Serial.print("%");
        if (i < 2) Serial.print(", ");
    }
    Serial.print("] ");
    int win = (myLogits[1] > myLogits[0]) ? 1 : 0;
    if (myLogits[2] > myLogits[win]) win = 2;
    return win;
}

void myProcessCamera(camera_fb_t *fb) {
    uint8_t *rgb = NULL;
    
    // Handle different pixel formats
    if (fb->format == PIXFORMAT_RGB888) {
        // Already in RGB888 format, no conversion needed
        rgb = fb->buf;
    } else {
        // Need to convert (JPEG or other format)
        rgb = (uint8_t *)ps_malloc(fb->width * fb->height * 3);
        if (!rgb) return;
        if (!fmt2rgb888(fb->buf, fb->len, fb->format, rgb)) { 
            free(rgb); 
            return; 
        }
    }
    
    float scaleY = (float)fb->height / 64.0f;
    float scaleX = (float)fb->width  / 64.0f;
    for (int y = 0; y < 64; y++) {
        float srcY = (y + 0.5f) * scaleY - 0.5f; int y0 = (int)srcY; int y1 = min(y0 + 1, (int)fb->height - 1); float dy = srcY - y0;
        for (int x = 0; x < 64; x++) {
            float srcX = (x + 0.5f) * scaleX - 0.5f; int x0 = (int)srcX; int x1 = min(x0 + 1, (int)fb->width - 1); float dx = srcX - x0;
            int idx00 = (y0 * fb->width + x0) * 3; int idx01 = (y0 * fb->width + x1) * 3;
            int idx10 = (y1 * fb->width + x0) * 3; int idx11 = (y1 * fb->width + x1) * 3;
            float r = (1.0f - dy) * ((1.0f - dx) * rgb[idx00] + dx * rgb[idx01]) + dy * ((1.0f - dx) * rgb[idx10] + dx * rgb[idx11]);
            float g = (1.0f - dy) * ((1.0f - dx) * rgb[idx00 + 1] + dx * rgb[idx01 + 1]) + dy * ((1.0f - dx) * rgb[idx10 + 1] + dx * rgb[idx11 + 1]);
            float b = (1.0f - dy) * ((1.0f - dx) * rgb[idx00 + 2] + dx * rgb[idx01 + 2]) + dy * ((1.0f - dx) * rgb[idx10 + 2] + dx * rgb[idx11 + 2]);
            #ifdef USE_GRAYSCALE_MODE
              float gray = (r * 0.299f) + (g * 0.587f) + (b * 0.114f);
              myInputBuffer[y * 64 + x] = gray / 255.0f; 
            #else
              int baseIdx = (y * 64 + x) * 3;
              myInputBuffer[baseIdx] = r / 255.0f; myInputBuffer[baseIdx + 1] = g / 255.0f; myInputBuffer[baseIdx + 2] = b / 255.0f;
            #endif
        }
    }
    
    // Free RGB buffer only if we allocated it (not if using RGB888 directly)
    if (fb->format != PIXFORMAT_RGB888) {
        free(rgb);
    }
}

void setup() {
    Serial.begin(115200);
    
    // Print model configuration at startup
    Serial.println("\n========== MODEL CONFIGURATION ==========");
    #ifdef USE_GRAYSCALE_MODE
      Serial.println("Color Mode: GRAYSCALE (1-channel)");
      Serial.print("Input Buffer Size: 64x64x1 = ");
      Serial.println(64*64*1);
    #else
      Serial.println("Color Mode: RGB (3-channel)");
      Serial.print("Input Buffer Size: 64x64x3 = ");
      Serial.println(64*64*3);
    #endif
    
    #ifdef USE_INT8_MODE
      Serial.println("Quantization: INT8");
      Serial.print("Conv1_w scale: "); Serial.println(myConv1_w_scale, 6);
      Serial.print("Conv2_w scale: "); Serial.println(myConv2_w_scale, 6);
      Serial.print("Output_w scale: "); Serial.println(myOutput_w_scale, 6);
    #else
      Serial.println("Quantization: FLOAT32");
    #endif
    
    Serial.println("\nClass Labels:");
    Serial.print("  0: "); Serial.println(myClassLabels[0]);
    Serial.print("  1: "); Serial.println(myClassLabels[1]);
    Serial.print("  2: "); Serial.println(myClassLabels[2]);
    
    Serial.println("\nModel Architecture:");
    Serial.println("  Conv1: 3x3 filters, 4 outputs -> 62x62x4");
    Serial.println("  MaxPool: 2x2 -> 31x31x4");
    Serial.println("  Conv2: 3x3 filters, 8 outputs -> 29x29x8");
    Serial.println("  Dense: 6728 -> 3 classes");
    
    Serial.print("\nTotal Parameters: ");
    #ifdef USE_GRAYSCALE_MODE
      int conv1Params = (3*3*1*4) + 4;
    #else
      int conv1Params = (3*3*3*4) + 4;
    #endif
    int conv2Params = (3*3*4*8) + 8;
    int denseParams = (29*29*8*3) + 3;
    Serial.println(conv1Params + conv2Params + denseParams);
    
    Serial.println("=========================================\n");
    Serial.println("DEBUG: Hold A0 high (>2000) for detailed frame analysis");
    Serial.println("Starting inference loop...\n");
    
    camera_config_t config;
    config.ledc_channel = LEDC_CHANNEL_0; config.ledc_timer = LEDC_TIMER_0;
    config.pin_d0 = Y2_GPIO_NUM; config.pin_d1 = Y3_GPIO_NUM; config.pin_d2 = Y4_GPIO_NUM; config.pin_d3 = Y5_GPIO_NUM;
    config.pin_d4 = Y6_GPIO_NUM; config.pin_d5 = Y7_GPIO_NUM; config.pin_d6 = Y8_GPIO_NUM; config.pin_d7 = Y9_GPIO_NUM;
    config.pin_xclk = XCLK_GPIO_NUM; config.pin_pclk = PCLK_GPIO_NUM; config.pin_vsync = VSYNC_GPIO_NUM;
    config.pin_href = HREF_GPIO_NUM; config.pin_sscb_sda = SIOD_GPIO_NUM; config.pin_sscb_scl = SIOC_GPIO_NUM;
    config.pin_pwdn = -1; config.pin_reset = -1; config.xclk_freq_hz = 10000000;
    config.frame_size = FRAMESIZE_QVGA; 
    
    // Try RGB888 first (uncompressed, best quality)
    // If memory issues occur, fall back to JPEG
    config.pixel_format = PIXFORMAT_RGB888;  // Changed from JPEG to RGB888 for better quality
    
    config.grab_mode = CAMERA_GRAB_LATEST; config.fb_location = CAMERA_FB_IN_PSRAM;
    config.fb_count = 1; config.jpeg_quality = 12;  // jpeg_quality ignored for RGB888
    
    if (esp_camera_init(&config) != ESP_OK) {
        Serial.println("RGB888 failed, trying JPEG...");
        config.pixel_format = PIXFORMAT_JPEG;  // Fallback to JPEG
        esp_camera_init(&config);
    } else {
        Serial.println("Camera initialized with RGB888 (uncompressed)");
    }
}

void loop() {
    camera_fb_t *fb = esp_camera_fb_get();
    if (!fb) return;
    myProcessCamera(fb);
    esp_camera_fb_return(fb);

    if (analogRead(A0) > 2000) {
        Serial.println("\n========== DETAILED DEBUG ==========");
        
        // 1. MODEL CONFIG REMINDER
        Serial.print("Mode: ");
        #ifdef USE_GRAYSCALE_MODE
          Serial.print("GRAYSCALE ");
        #else
          Serial.print("RGB ");
        #endif
        #ifdef USE_INT8_MODE
          Serial.println("INT8");
        #else
          Serial.println("FLOAT32");
        #endif
        
        // Show camera format
        Serial.print("Camera Format: ");
        if (fb->format == PIXFORMAT_RGB888) Serial.println("RGB888 (uncompressed)");
        else if (fb->format == PIXFORMAT_JPEG) Serial.println("JPEG (compressed)");
        else if (fb->format == PIXFORMAT_RGB565) Serial.println("RGB565");
        else if (fb->format == PIXFORMAT_GRAYSCALE) Serial.println("GRAYSCALE");
        else Serial.println("UNKNOWN");
        
        // 2. INPUT BUFFER STATS
        float minVal = 10.0, maxVal = -10.0, avgVal = 0.0;
        int totalPixels = 64 * 64 * (
          #ifdef USE_GRAYSCALE_MODE
            1
          #else
            3
          #endif
        );
        for (int i = 0; i < totalPixels; i++) {
            float val = myInputBuffer[i];
            if (val < minVal) minVal = val; 
            if (val > maxVal) maxVal = val; 
            avgVal += val;
        }
        avgVal /= totalPixels;
        Serial.print("INPUT - Min: "); Serial.print(minVal, 4); 
        Serial.print(" Max: "); Serial.print(maxVal, 4); 
        Serial.print(" Avg: "); Serial.print(avgVal, 4);
        Serial.print(" Range: "); Serial.print(maxVal - minVal, 4);
        // NOTE: Min should be close to 0.0 only if scene has pure black pixels
        // Typical indoor scenes have ambient light, so min ~0.20-0.25 is normal
        if (minVal > 0.3f) Serial.print(" [HIGH - check lighting/exposure]");
        Serial.println();

        // 3. LAYER STATISTICS
        auto printLayerStats = [](const char* name, float* buf, int len) {
            float mi = 1e6, ma = -1e6, av = 0; 
            int z = 0, neg = 0, clipped = 0;
            for(int i=0; i<len; i++){
                float v = buf[i]; 
                if(v < mi) mi = v; 
                if(v > ma) ma = v; 
                av += v; 
                if(v == 0.0f) z++;
                if(v < 0.0f) neg++;
                if(v == -100.0f || v == 100.0f) clipped++;
            }
            av /= len;
            Serial.print(name); 
            Serial.print(" - Min: "); Serial.print(mi, 2); 
            Serial.print(" Max: "); Serial.print(ma, 2); 
            Serial.print(" Avg: "); Serial.print(av, 2);
            Serial.print(" Neg: "); Serial.print(neg); 
            Serial.print("/"); Serial.print(len); 
            Serial.print(" ("); Serial.print((neg*100)/len); Serial.print("%)");
            Serial.print(" Zeros: "); Serial.print(z); 
            Serial.print("/"); Serial.print(len); 
            Serial.print(" ("); Serial.print((z*100)/len); Serial.print("%)");
            if(clipped > 0) {
                Serial.print(" CLIPPED: "); Serial.print(clipped);
            }
            Serial.println();
        };
        
        printLayerStats("CONV1", myConv1Output, 62*62*4);
        printLayerStats("POOL1", myPool1Output, 31*31*4);
        printLayerStats("CONV2", myConv2Output, 29*29*8);

        // 4. WEIGHT SAMPLES
        Serial.println("\nWeight Samples:");
        Serial.print("  Conv1_w[0-5]: ");
        for (int i = 0; i < 6; i++) { 
            Serial.print(GET_W(myConv1_w, i, myConv1_w_scale), 4); 
            Serial.print(" "); 
        }
        Serial.println();
        
        Serial.print("  Conv1_b[0-3]: ");
        for (int i = 0; i < 4; i++) { 
            Serial.print(GET_W(myConv1_b, i, myConv1_b_scale), 4); 
            Serial.print(" "); 
        }
        Serial.println();
        
        Serial.print("  Output_w[0-9]: ");
        for (int i = 0; i < 10; i++) { 
            Serial.print(GET_W(myOutput_w, i, myOutput_w_scale), 4); 
            Serial.print(" "); 
        }
        Serial.println();
        
        Serial.print("  Output_b[0-2]: ");
        for (int i = 0; i < 3; i++) { 
            Serial.print(GET_W(myOutput_b, i, myOutput_b_scale), 4); 
            Serial.print(" "); 
        }
        Serial.println();
        
        // 4b. DEEP WEIGHT ANALYSIS
        Serial.println("\n--- Deep Weight Check ---");
        
        // Count Conv1 weights
        #ifdef USE_GRAYSCALE_MODE
          int conv1WeightCount = 3*3*1*4;  // 36 weights
        #else
          int conv1WeightCount = 3*3*3*4;  // 108 weights
        #endif
        Serial.print("Conv1 expected weights: "); Serial.println(conv1WeightCount);
        
        // Sample Conv1 weights at different positions
        Serial.print("Conv1_w[middle 54]: "); Serial.println(GET_W(myConv1_w, 54, myConv1_w_scale), 4);
        Serial.print("Conv1_w[last]: "); Serial.println(GET_W(myConv1_w, conv1WeightCount-1, myConv1_w_scale), 4);
        
        // Conv2 weights
        int conv2WeightCount = 3*3*4*8;  // 288 weights
        Serial.print("Conv2 expected weights: "); Serial.println(conv2WeightCount);
        Serial.print("Conv2_w[0-2]: ");
        for (int i = 0; i < 3; i++) {
            Serial.print(GET_W(myConv2_w, i, myConv2_w_scale), 4); Serial.print(" ");
        }
        Serial.println();
        Serial.print("Conv2_w[last]: "); Serial.println(GET_W(myConv2_w, conv2WeightCount-1, myConv2_w_scale), 4);
        
        // Output weights
        int outputWeightCount = 29*29*8*3;  // 20232 weights
        Serial.print("Output expected weights: "); Serial.println(outputWeightCount);
        Serial.print("Output_w[1000]: "); Serial.println(GET_W(myOutput_w, 1000, myOutput_w_scale), 4);
        Serial.print("Output_w[10000]: "); Serial.println(GET_W(myOutput_w, 10000, myOutput_w_scale), 4);
        Serial.print("Output_w[last]: "); Serial.println(GET_W(myOutput_w, outputWeightCount-1, myOutput_w_scale), 4);

        // 4c. CONVOLUTION SANITY CHECK
        Serial.println("\n--- Conv1 Single Pixel Test ---");
        // Test one pixel computation manually
        float testSum = 0;
        int testY = 10, testX = 10, testFilter = 0;
        #ifdef USE_GRAYSCALE_MODE
          for (int ky = 0; ky < 3; ky++) {
              for (int kx = 0; kx < 3; kx++) {
                  int pIdx = (testY+ky)*64 + (testX+kx);
                  int wIdx = (testFilter*9) + (ky*3) + kx;
                  float pixVal = myInputBuffer[pIdx];
                  float weight = GET_W(myConv1_w, wIdx, myConv1_w_scale);
                  testSum += pixVal * weight;
                  if (ky == 1 && kx == 1) {  // Center pixel
                      Serial.print("  Center pixel: input="); Serial.print(pixVal, 4);
                      Serial.print(" weight="); Serial.println(weight, 4);
                  }
              }
          }
        #else
          for (int ky = 0; ky < 3; ky++) {
              for (int kx = 0; kx < 3; kx++) {
                  int pIdx = ((testY+ky)*64 + (testX+kx))*3;
                  int wIdx = (testFilter*27) + (ky*9) + (kx*3);
                  float r = myInputBuffer[pIdx];
                  float g = myInputBuffer[pIdx+1];
                  float b = myInputBuffer[pIdx+2];
                  float wr = GET_W(myConv1_w, wIdx, myConv1_w_scale);
                  float wg = GET_W(myConv1_w, wIdx+1, myConv1_w_scale);
                  float wb = GET_W(myConv1_w, wIdx+2, myConv1_w_scale);
                  testSum += r*wr + g*wg + b*wb;
                  if (ky == 1 && kx == 1) {  // Center pixel
                      Serial.print("  Center pixel RGB: ["); 
                      Serial.print(r, 3); Serial.print(","); 
                      Serial.print(g, 3); Serial.print(","); 
                      Serial.print(b, 3); Serial.println("]");
                      Serial.print("  Weights RGB: [");
                      Serial.print(wr, 4); Serial.print(",");
                      Serial.print(wg, 4); Serial.print(",");
                      Serial.print(wb, 4); Serial.println("]");
                  }
              }
          }
        #endif
        testSum += GET_W(myConv1_b, testFilter, myConv1_b_scale);
        float testOutput = (testSum > 0) ? testSum : (0.1f * testSum);
        Serial.print("Manual Conv1 output at ["); Serial.print(testY); Serial.print(","); Serial.print(testX);
        Serial.print("] filter 0: "); Serial.print(testOutput, 4);
        Serial.print(" (stored value: "); Serial.print(myConv1Output[testFilter*3844 + testY*62 + testX], 4);
        Serial.println(")");

        // 5. LOGITS BEFORE SOFTMAX
        Serial.println("\nLogits (before softmax):");
        float myLogits[3] = {0, 0, 0};
        int totalFeatures = 29 * 29 * 8;
        for (int i = 0; i < 3; i++) {
            double sum = 0.0; 
            double compensation = 0.0;
            for (int j = 0; j < totalFeatures; j++) {
                double term = (double)myConv2Output[j] * GET_W(myOutput_w, i*totalFeatures + j, myOutput_w_scale);
                double y = term - compensation; 
                double t = sum + y;
                compensation = (t - sum) - y; 
                sum = t;
            }
            myLogits[i] = clipValue((float)sum + GET_W(myOutput_b, i, myOutput_b_scale), -50.0f, 50.0f);
            Serial.print("  Class "); Serial.print(i); 
            Serial.print(" ("); Serial.print(myClassLabels[i]); 
            Serial.print("): "); Serial.print(myLogits[i], 4);
            // NOTE: If all logits are very negative (< -10), model may be undertrained
            // Try: More samples, lower learning rate, or more epochs
            if (myLogits[i] < -10.0f) Serial.print(" [VERY LOW]");
            Serial.println();
        }

        // 6. ASCII PREVIEW
        Serial.println("\n--- ASCII PREVIEW (32x16) ---");
        for (int y = 0; y < 64; y += 4) {
            for (int x = 0; x < 64; x += 2) {
                float val;
                #ifdef USE_GRAYSCALE_MODE
                  val = myInputBuffer[y * 64 + x];
                #else
                  int idx = (y * 64 + x) * 3;
                  val = (myInputBuffer[idx] + myInputBuffer[idx+1] + myInputBuffer[idx+2]) / 3.0f;
                #endif
                if (val > 0.75) Serial.print("#"); 
                else if (val > 0.5) Serial.print("+"); 
                else if (val > 0.25) Serial.print("."); 
                else Serial.print(" ");
            }
            Serial.println();
        }
        
        // 7. MEMORY INFO
        Serial.println("\n--- Memory Usage ---");
        Serial.print("Free Heap: "); Serial.print(ESP.getFreeHeap()); Serial.println(" bytes");
        Serial.print("Free PSRAM: "); Serial.print(ESP.getFreePsram()); Serial.println(" bytes");
        
        Serial.println("========== END DEBUG ==========\n");
        delay(2000);
    }

    myConv1(); myMaxPool1(); myConv2();
    int result = myGetWinner();
    Serial.print("Class: "); Serial.print(result); 
    Serial.print(" ("); Serial.print(myClassLabels[result]); Serial.println(")");
    delay(50);
}

  
</textarea>














  

<h2>By Jeremy Ellis, Use at your own Risk</h2>
<a href="https://github.com/hpssjellis">github Profile hpssjellis</a><br>
<a href="https://www.linkedin.com/in/jeremy-ellis-4237a9bb/">LinkedIn jeremy-ellis-4237a9bb</a> <br>
<a href="https://opencollective.com/mlsysbook">Support the opencollective.com/mlsysbook</a> <br>
<a href="https://github.com/hpssjellis/my-examples-of-tensorflowjs-for-tinytorch">This Github is at:my-examples-of-tensorflowjs-for-tinytorch </a> <br>
<a href="https://www.seeedstudio.com/The-XIAOML-Kit.html">The $22 USD xiaoMLkit ($38 USD if you need a usbC cable and an sd Card)</a> <br>





  
</body>
