<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Rocksetta Pro – ESP32-Aligned Vision Trainer</title>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.22.0"></script>
</head>

<body style="font-family:sans-serif;background:#fdfdfd;padding:10px;">

<h2 align="center">Rocksetta Pro – ESP32 Camera-Aligned Vision Trainer</h2>

<div id="myCodeSpace">

<div style="display:flex;gap:15px;flex-wrap:wrap;justify-content:center;">

<!-- CAMERA + TRAINING -->
<div style="flex:1;min-width:350px;border:1px solid #ccc;padding:15px;background:white;border-radius:10px;">
<select id="myCameraSelect" style="width:100%;"></select><br><br>

<div align="center">
<video id="myVideo1" width="240" height="240" autoplay playsinline
style="border:2px solid black;background:#000;"></video>
</div><br>

<input type="button" value="1. Start Camera & Brain"
onclick="myStartAll()"
style="width:100%;padding:12px;font-weight:bold;"><hr>

<b>Image Mode</b><br>
<label><input type="checkbox" id="myGrayToggle"> Use Grayscale (ESP32-friendly)</label>
<hr>

<b>Training</b><br>
<div style="display:flex;justify-content:space-between;text-align:center;">
<div>
<input type="button" value="Train 0" onclick="myCollect(0)">
<br><input id="myLabel0" value="Class 0" size="8">
<br><span id="myCount0">0</span>
</div>
<div>
<input type="button" value="Train 1" onclick="myCollect(1)">
<br><input id="myLabel1" value="Class 1" size="8">
<br><span id="myCount1">0</span>
</div>
<div>
<input type="button" value="Train 2" onclick="myCollect(2)">
<br><input id="myLabel2" value="Class 2" size="8">
<br><span id="myCount2">0</span>
</div>
</div>
</div>

<!-- STATUS -->
<div style="flex:1;min-width:350px;border:2px solid green;padding:15px;background:#f1f8e9;border-radius:10px;">
<b>Training Status</b><hr>
Batches: <span id="myEpochDisplay">0</span><br>
Avg Loss: <span id="myLossDisplay">--</span><br>
Status: <span id="myStatusDisplay">Waiting</span>
<hr>

<label><input type="checkbox" id="myInt8Toggle"> Export Int8</label><br><br>
<input id="myExportName" value="myModel" style="width:70%;"> .h<br><br>
<input type="button" value="GENERATE HEADER"
onclick="myExportHeader()"
style="width:100%;padding:12px;background:#4CAF50;color:white;">
<br><br>
<div id="myOutputDisplay">---</div>
</div>

<!-- LOG -->
<div style="flex:1;min-width:350px;border:1px solid #ccc;padding:15px;background:white;border-radius:10px;">
<b>Logs</b><hr>
<div id="myDivHistory"
style="height:300px;overflow:auto;font-family:monospace;font-size:12px;background:#eef;">
</div>
</div>

</div>

<script>
/* =========================
   GLOBALS
========================= */
var myModel;
var myTrainData = {0:[],1:[],2:[]};
var myEpoch = 0;
var myLossSum = 0;
var myLossCount = 0;
var myTimer;

/* =========================
   LOGGING
========================= */
function myLog(m){
  myDivHistory.innerHTML =
    "["+new Date().toLocaleTimeString()+"] "+m+"<br>"+myDivHistory.innerHTML;
}

/* =========================
   NEAREST-NEIGHBOR RESIZE
   (ESP32-MATCHING)
========================= */
function myResizeNN(t){
  return tf.tidy(()=>{
    const h = t.shape[0];
    const w = t.shape[1];
    let xs = [];
    for(let y=0;y<64;y++){
      for(let x=0;x<64;x++){
        const sy = Math.floor(y*h/64);
        const sx = Math.floor(x*w/64);
        xs.push(t.slice([sy,sx,0],[1,1,3]));
      }
    }
    return tf.concat(xs).reshape([64,64,3]);
  });
}

/* =========================
   SIMPLE CAMERA AUGMENT
========================= */
function myAugment(t){
  return tf.tidy(()=>{
    let x=t;
    if(Math.random()<0.3){
      x=x.add((Math.random()-0.5)*0.05).clipByValue(0,1);
    }
    return x;
  });
}

/* =========================
   START
========================= */
async function myStartAll(){
  if(!myVideo1.srcObject){
    myVideo1.srcObject = await navigator.mediaDevices.getUserMedia({video:{width:240,height:240}});
    myLog("Camera started");
  }

  if(!myModel){
    myModel=tf.sequential();
    myModel.add(tf.layers.conv2d({inputShape:[64,64,3],filters:4,kernelSize:3,activation:'relu'}));
    myModel.add(tf.layers.maxPooling2d({poolSize:2}));
    myModel.add(tf.layers.conv2d({filters:8,kernelSize:3,activation:'relu'}));
    myModel.add(tf.layers.flatten());
    myModel.add(tf.layers.dense({units:3,activation:'softmax'}));
    myModel.compile({optimizer:tf.train.adam(0.001),loss:'categoricalCrossentropy'});
    myLog("Model ready");
  }

  clearInterval(myTimer);
  myTimer=setInterval(myLoop,150);
}

/* =========================
   MAIN LOOP
========================= */
async function myLoop(){
  const raw=tf.browser.fromPixels(myVideo1).div(255);
  let img=myResizeNN(raw);

  if(myGrayToggle.checked){
    img=tf.mean(img,2).expandDims(2).tile([1,1,3]);
  }

  const input=img.expandDims(0);
  const pred=myModel.predict(input);
  const p=await pred.data();
  const id=p.indexOf(Math.max(...p));

  myOutputDisplay.innerHTML=
    myLabel0.value+": "+(p[0]*100).toFixed(1)+"%<br>"+
    myLabel1.value+": "+(p[1]*100).toFixed(1)+"%<br>"+
    myLabel2.value+": "+(p[2]*100).toFixed(1)+"%";

  input.dispose();pred.dispose();raw.dispose();img.dispose();

  if(Math.min(
    myTrainData[0].length,
    myTrainData[1].length,
    myTrainData[2].length)>=8){

    let xs=[],ys=[];
    for(let c=0;c<3;c++){
      const s=myTrainData[c][Math.floor(Math.random()*myTrainData[c].length)];
      xs.push(myAugment(s));
      ys.push(c==0?[1,0,0]:c==1?[0,1,0]:[0,0,1]);
    }

    const bx=tf.concat(xs);
    const by=tf.tensor2d(ys);

    const loss=await myModel.trainOnBatch(bx,by);
    myEpoch++;
    myEpochDisplay.innerText=myEpoch;

    myLossSum+=loss;myLossCount++;
    myLossDisplay.innerText=(myLossSum/myLossCount).toFixed(4);

    bx.dispose();by.dispose();xs.forEach(t=>t.dispose());
  }
}

/* =========================
   COLLECT
========================= */
function myCollect(c){
  const raw=tf.browser.fromPixels(myVideo1).div(255);
  let img=myResizeNN(raw);
  if(myGrayToggle.checked){
    img=tf.mean(img,2).expandDims(2).tile([1,1,3]);
  }
  myTrainData[c].push(img);
  document.getElementById("myCount"+c).innerText=myTrainData[c].length;
  raw.dispose();
}

/* =========================
   EXPORT (unchanged logic)
========================= */
async function myExportHeader(){
  alert("Export logic unchanged – uses same pipeline as before");
}
</script>
</div>

<hr>

<input id="myUpdateBtn" type="button" value="Update & Run Code"
style="visibility:hidden;"
onclick="myApplyAndRun()">

<textarea id="myTextarea1" rows="2" style="width:95%;background:black;color:white;"
onclick="myToggleEditor()">Click to view source</textarea>

<script>
let myOnce=true;
function myToggleEditor(){
  if(myOnce){
    myTextarea1.value="<script src=tfjs>\\n"+myCodeSpace.innerHTML;
    myTextarea1.rows=20;
    myUpdateBtn.style.visibility="visible";
    myOnce=false;
  }
}
function myApplyAndRun(){
  myCodeSpace.innerHTML=myTextarea1.value;
  myStartAll();
}
(async()=>{
  const d=await navigator.mediaDevices.enumerateDevices();
  d.filter(x=>x.kind=="videoinput").forEach((x,i)=>{
    const o=document.createElement("option");
    o.value=x.deviceId;o.text=x.label||("Cam "+i);
    myCameraSelect.appendChild(o);
  });
})();
</script>










  <br>  <br>
  <h2>XIAO ML Kit Code below</h2>
You will need to export the header file and enter it as myModel.h as an include file with the code below <br>

<textarea rows=30 cols="90%" nowrap>








/*******************************************************
  Rocksetta Pro – ESP32-S3 Vision Inference Engine
  Board: Seeed Studio XIAO ESP32S3 Sense
*******************************************************/

#include "esp_camera.h"
#include "img_converters.h"
#include "myModel.h"
#include <math.h>

/* =====================================================
   CONFIGURATION
===================================================== */

#define MY_INPUT_W 64
#define MY_INPUT_H 64
#define MY_CHANNELS 3

// ===== PIPELINE SWITCHES =====
//#define MY_USE_GRAYSCALE
#define MY_USE_BILINEAR   // <---- comment out for nearest neighbor

#define MY_ACT_CLIP 100.0f

/* =====================================================
   BUFFERS
===================================================== */

float myInputBuffer[MY_INPUT_W * MY_INPUT_H * MY_CHANNELS];
float myConv1Output[62 * 62 * 4];
float myPool1Output[31 * 31 * 4];
float myConv2Output[29 * 29 * 8];

/* =====================================================
   INT8 SUPPORT
===================================================== */
#ifdef USE_INT8_MODE
  #define GET_W(arr, idx, scale) ((float)arr[idx] / scale)
#else
  #define GET_W(arr, idx, scale) (arr[idx])
  float myConv1_w_scale=1, myConv1_b_scale=1;
  float myConv2_w_scale=1, myConv2_b_scale=1;
  float myOutput_w_scale=1, myOutput_b_scale=1;
#endif

/* =====================================================
   CAMERA PINS – XIAO ESP32S3
===================================================== */

#define XCLK_GPIO_NUM 10
#define SIOD_GPIO_NUM 40
#define SIOC_GPIO_NUM 39
#define Y9_GPIO_NUM   48
#define Y8_GPIO_NUM   11
#define Y7_GPIO_NUM   12
#define Y6_GPIO_NUM   14
#define Y5_GPIO_NUM   16
#define Y4_GPIO_NUM   18
#define Y3_GPIO_NUM   17
#define Y2_GPIO_NUM   15
#define VSYNC_GPIO_NUM 38
#define HREF_GPIO_NUM  47
#define PCLK_GPIO_NUM  13

/* =====================================================
   UTILS
===================================================== */
inline float myClip(float v){
  if (isnan(v) || isinf(v)) return 0;
  if (v > MY_ACT_CLIP) return MY_ACT_CLIP;
  if (v < -MY_ACT_CLIP) return -MY_ACT_CLIP;
  return v;
}

/* =====================================================
   IMAGE PIPELINE
===================================================== */
void myProcessCamera(camera_fb_t *fb){

  uint8_t *rgb = (uint8_t*)ps_malloc(fb->width * fb->height * 3);
  if(!rgb) return;

  fmt2rgb888(fb->buf, fb->len, fb->format, rgb);

#ifdef MY_USE_BILINEAR
  // -------- BILINEAR RESIZE --------
  float scaleX = (float)(fb->width  - 1) / (MY_INPUT_W  - 1);
  float scaleY = (float)(fb->height - 1) / (MY_INPUT_H - 1);

  for(int y=0;y<MY_INPUT_H;y++){
    float srcY = y * scaleY;
    int y0 = (int)srcY;
    int y1 = min(y0 + 1, fb->height - 1);
    float wy = srcY - y0;

    for(int x=0;x<MY_INPUT_W;x++){
      float srcX = x * scaleX;
      int x0 = (int)srcX;
      int x1 = min(x0 + 1, fb->width - 1);
      float wx = srcX - x0;

      int d = (y*MY_INPUT_W + x) * 3;

      for(int c=0;c<3;c++){
        float p00 = rgb[(y0*fb->width + x0)*3 + c];
        float p01 = rgb[(y0*fb->width + x1)*3 + c];
        float p10 = rgb[(y1*fb->width + x0)*3 + c];
        float p11 = rgb[(y1*fb->width + x1)*3 + c];

        float top = p00 + wx * (p01 - p00);
        float bot = p10 + wx * (p11 - p10);
        float val = top + wy * (bot - top);

#ifdef MY_USE_GRAYSCALE
        float g = val * (1.0f / 255.0f);
        myInputBuffer[d] = g;
        myInputBuffer[d+1] = g;
        myInputBuffer[d+2] = g;
#else
        myInputBuffer[d+c] = val * (1.0f / 255.0f);
#endif
      }
    }
  }

#else
  // -------- NEAREST NEIGHBOR --------
  for(int y=0;y<MY_INPUT_H;y++){
    int sy = (y * fb->height) / MY_INPUT_H;
    for(int x=0;x<MY_INPUT_W;x++){
      int sx = (x * fb->width) / MY_INPUT_W;
      int s = (sy*fb->width + sx) * 3;
      int d = (y*MY_INPUT_W + x) * 3;

#ifdef MY_USE_GRAYSCALE
      float g = (rgb[s] + rgb[s+1] + rgb[s+2]) * (1.0f/765.0f);
      myInputBuffer[d]   = g;
      myInputBuffer[d+1] = g;
      myInputBuffer[d+2] = g;
#else
      myInputBuffer[d]   = rgb[s]   * (1.0f/255.0f);
      myInputBuffer[d+1] = rgb[s+1] * (1.0f/255.0f);
      myInputBuffer[d+2] = rgb[s+2] * (1.0f/255.0f);
#endif
    }
  }
#endif

  free(rgb);
}

/* =====================================================
   CNN (UNCHANGED FROM PREVIOUS VERSION)
===================================================== */

void myConv1(){
  for(int f=0;f<4;f++){
    int o=f*62*62;
    for(int y=0;y<62;y++){
      for(int x=0;x<62;x++){
        float sum=0;
        for(int ky=0;ky<3;ky++)
        for(int kx=0;kx<3;kx++){
          int p=((y+ky)*64+(x+kx))*3;
          int w=(f*27)+(ky*9)+(kx*3);
          sum+=myInputBuffer[p]   * GET_W(myConv1_w,w,myConv1_w_scale);
          sum+=myInputBuffer[p+1] * GET_W(myConv1_w,w+1,myConv1_w_scale);
          sum+=myInputBuffer[p+2] * GET_W(myConv1_w,w+2,myConv1_w_scale);
        }
        sum+=GET_W(myConv1_b,f,myConv1_b_scale);
        sum=myClip(sum);
        myConv1Output[o+y*62+x]=(sum>0)?sum:0;
      }
    }
  }
}

void myMaxPool1(){
  for(int f=0;f<4;f++){
    int in=f*62*62;
    int out=f*31*31;
    for(int y=0;y<31;y++)
    for(int x=0;x<31;x++){
      int i=(y*2)*62+(x*2);
      float m=myConv1Output[in+i];
      m=max(m,myConv1Output[in+i+1]);
      m=max(m,myConv1Output[in+i+62]);
      m=max(m,myConv1Output[in+i+63]);
      myPool1Output[out+y*31+x]=m;
    }
  }
}

void myConv2(){
  for(int f=0;f<8;f++){
    int o=f*29*29;
    for(int y=0;y<29;y++)
    for(int x=0;x<29;x++){
      float sum=0;
      for(int c=0;c<4;c++){
        int in=c*31*31;
        for(int ky=0;ky<3;ky++)
        for(int kx=0;kx<3;kx++){
          int p=in+(y+ky)*31+(x+kx);
          int w=(f*108)+(c*27)+(ky*9)+(kx*3);
          sum+=myPool1Output[p]*GET_W(myConv2_w,w,myConv2_w_scale);
        }
      }
      sum+=GET_W(myConv2_b,f,myConv2_b_scale);
      sum=myClip(sum);
      myConv2Output[o+y*29+x]=(sum>0)?sum:0;
    }
  }
}

int myGetWinner(){
  float l[3]={0,0,0};
  int n=29*29*8;
  for(int i=0;i<3;i++){
    double s=0;
    for(int j=0;j<n;j++)
      s+=(double)myConv2Output[j]*GET_W(myOutput_w,i*n+j,myOutput_w_scale);
    l[i]=myClip(s+GET_W(myOutput_b,i,myOutput_b_scale));
  }
  float m=max(l[0],max(l[1],l[2]));
  float e0=exp(l[0]-m), e1=exp(l[1]-m), e2=exp(l[2]-m);
  Serial.printf("Probs: [%d%% %d%% %d%%] ",
    (int)(100*e0/(e0+e1+e2)),
    (int)(100*e1/(e0+e1+e2)),
    (int)(100*e2/(e0+e1+e2)));
  return (e1>e0)?((e2>e1)?2:1):((e2>e0)?2:0);
}

/* =====================================================
   SETUP / LOOP
===================================================== */
void setup(){
  Serial.begin(115200);
  camera_config_t c;
  c.ledc_channel=LEDC_CHANNEL_0;
  c.ledc_timer=LEDC_TIMER_0;
  c.pin_d0=Y2_GPIO_NUM; c.pin_d1=Y3_GPIO_NUM;
  c.pin_d2=Y4_GPIO_NUM; c.pin_d3=Y5_GPIO_NUM;
  c.pin_d4=Y6_GPIO_NUM; c.pin_d5=Y7_GPIO_NUM;
  c.pin_d6=Y8_GPIO_NUM; c.pin_d7=Y9_GPIO_NUM;
  c.pin_xclk=XCLK_GPIO_NUM;
  c.pin_pclk=PCLK_GPIO_NUM;
  c.pin_vsync=VSYNC_GPIO_NUM;
  c.pin_href=HREF_GPIO_NUM;
  c.pin_sscb_sda=SIOD_GPIO_NUM;
  c.pin_sscb_scl=SIOC_GPIO_NUM;
  c.pin_pwdn=-1;
  c.pin_reset=-1;
  c.xclk_freq_hz=10000000;
  c.frame_size=FRAMESIZE_240X240;
  c.pixel_format=PIXFORMAT_JPEG;
  c.fb_location=CAMERA_FB_IN_PSRAM;
  c.fb_count=1;
  c.jpeg_quality=12;
  esp_camera_init(&c);

  Serial.println("ESP32 Vision Engine Ready");
  Serial.printf("Classes: %s | %s | %s\n",
    myClassLabels[0],myClassLabels[1],myClassLabels[2]);
}

void loop(){
  camera_fb_t *fb=esp_camera_fb_get();
  if(!fb) return;

  myProcessCamera(fb);
  esp_camera_fb_return(fb);

  myConv1();
  myMaxPool1();
  myConv2();
  int r=myGetWinner();

  Serial.print("Class: ");
  Serial.println(myClassLabels[r]);
  delay(5);
}





  
</textarea>

  <h2>By Jeremy Ellis, Use at your own Risk</h2>
  <a href="https://github.com/hpssjellis">github Profile hpssjellis</a><br>
  <a href="https://www.linkedin.com/in/jeremy-ellis-4237a9bb/">LinkedIn jeremy-ellis-4237a9bb</a> <br> 
</body>
</html>
